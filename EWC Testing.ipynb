{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from IPython.display import clear_output, display\n",
    "import torch\n",
    "import random\n",
    "import copy\n",
    "import time\n",
    "import os #to get current working directory\n",
    "import matplotlib.pyplot as plt\n",
    "import pickle #for storing data\n",
    "from wurm.envs import SingleSnake\n",
    "from wurm.envs import SimpleGridworld\n",
    "from gym.wrappers.monitoring.video_recorder import VideoRecorder\n",
    "\n",
    "DEFAULT_DEVICE = 'cuda' #set device"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Visualizing the neural network. Requires Tensorboard"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "from torch.utils.tensorboard import SummaryWriter\n",
    "writer = SummaryWriter()\n",
    "writer.add_graph(qnet, torch.Tensor(env.reset()))\n",
    "writer.close()\n",
    "%load_ext tensorboard\n",
    "%tensorboard --logdir=runs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Replay Buffer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import collections\n",
    "\n",
    "class ReplayBuffer():\n",
    "    def __init__(self, max_buffer_size: int):\n",
    "        #data must be of the form (state,next_state,action,reward,terminal)\n",
    "        self.buffer = collections.deque(maxlen=max_buffer_size)\n",
    "\n",
    "    def add_to_buffer(self, data):\n",
    "        #data must be of the form (state,next_state,action,reward,terminal)\n",
    "        self.buffer.append(data)\n",
    "    def clear_buffer(self):\n",
    "        self.buffer.clear()\n",
    "        \n",
    "    #Sample superbatches and sub sample parallel environments\n",
    "    def sample_subbatch(self,superbatch_length, subbatch_length):\n",
    "        states = []\n",
    "        next_states = []\n",
    "        actions = []\n",
    "        rewards = []\n",
    "        terminals = []\n",
    "        sub_length = self.buffer[0][0].shape[0]\n",
    "        for rand_int in np.random.randint(0, len(self.buffer), superbatch_length):\n",
    "            rand_int_1 = np.random.randint(0, sub_length, subbatch_length)\n",
    "            transition = self.buffer[rand_int]\n",
    "            states.append(transition[0][rand_int_1])\n",
    "            next_states.append(transition[1][rand_int_1])\n",
    "            actions.append(transition[2][rand_int_1])\n",
    "            rewards.append(transition[3][rand_int_1])\n",
    "            terminals.append(transition[4][rand_int_1])\n",
    "        return torch.cat(states), torch.cat(next_states), torch.cat(actions), torch.cat(rewards), torch.cat(terminals)\n",
    "\n",
    "    def sample_superbatch(self,superbatch_length):\n",
    "        states = []\n",
    "        next_states = []\n",
    "        actions = []\n",
    "        rewards = []\n",
    "        terminals = []\n",
    "        for rand_int in np.random.randint(0, len(self.buffer), superbatch_length):\n",
    "            transition = self.buffer[rand_int]\n",
    "            states.append(transition[0])\n",
    "            next_states.append(transition[1])\n",
    "            actions.append(transition[2])\n",
    "            rewards.append(transition[3])\n",
    "            terminals.append(transition[4])\n",
    "        return torch.cat(states), torch.cat(next_states), torch.cat(actions), torch.cat(rewards), torch.cat(terminals)\n",
    "    \n",
    "    #sample parallel environments of subbatch_length from a randomly selected buffer location.\n",
    "    def sample(self, subbatch_length):\n",
    "            rand_int = np.random.randint(0, len(self.buffer))\n",
    "            rand_int_1 = np.random.randint(0, len(self.buffer[0][0]), subbatch_length)\n",
    "            transition = self.buffer[rand_int]\n",
    "            states=transition[0][rand_int_1]\n",
    "            next_states=transition[1][rand_int_1]\n",
    "            actions=transition[2][rand_int_1]\n",
    "            rewards=transition[3][rand_int_1]\n",
    "            terminals=transition[4][rand_int_1]\n",
    "            return (states,next_states,actions,rewards,terminals)\n",
    "\n",
    "        \n",
    "#A buffer with lesser correlation between samples. Implemented with pytorch. \n",
    "#Presently not working properly. Not sure why.\n",
    "class BetterBuffer():\n",
    "    def __init__(self, max_envs: int = 1000):\n",
    "        #data must be of the form (state,next_state,action,reward,terminal)\n",
    "        self.buffer_0 = torch.empty(0).to(DEFAULT_DEVICE)\n",
    "        self.buffer_1 = torch.empty(0).to(DEFAULT_DEVICE)\n",
    "        self.buffer_2 = torch.empty(0).long().to(DEFAULT_DEVICE)\n",
    "        self.buffer_3 = torch.empty(0).to(DEFAULT_DEVICE)\n",
    "        self.buffer_4 = torch.empty(0).bool().to(DEFAULT_DEVICE)\n",
    "        self.max_length = max_envs\n",
    "        self.pointer = 0\n",
    "        self.full = False\n",
    "\n",
    "    def add_to_buffer(self, data):\n",
    "        #data must be of the form (state,next_state,action,reward,terminal)\n",
    "        if self.full == True:\n",
    "            if self.pointer==self.max_length:\n",
    "                self.pointer=0\n",
    "            self.buffer_0[self.pointer*num_envs:(self.pointer+1)*num_envs] = data[0]\n",
    "            self.buffer_1[self.pointer*num_envs:(self.pointer+1)*num_envs] = data[1]\n",
    "            self.buffer_2[self.pointer*num_envs:(self.pointer+1)*num_envs] = data[2]\n",
    "            self.buffer_3[self.pointer*num_envs:(self.pointer+1)*num_envs] = data[3]\n",
    "            self.buffer_4[self.pointer*num_envs:(self.pointer+1)*num_envs] = data[4]\n",
    "            self.pointer+=1\n",
    "        else:\n",
    "            self.buffer_0=torch.cat((self.buffer_0,data[0]))\n",
    "            self.buffer_1=torch.cat((self.buffer_1,data[1]))\n",
    "            self.buffer_2=torch.cat((self.buffer_2,data[2]))\n",
    "            self.buffer_3=torch.cat((self.buffer_3,data[3]))\n",
    "            self.buffer_4=torch.cat((self.buffer_4,data[4]))\n",
    "            self.pointer+=1\n",
    "            if self.pointer==self.max_length:\n",
    "                self.full=True\n",
    "        \n",
    "    def sample(self, batch_size):\n",
    "        if self.full == True:\n",
    "            randint = torch.randint(0, self.max_length*num_envs,(batch_size,))\n",
    "        else:\n",
    "            randint = torch.randint(0,self.pointer*num_envs, (batch_size,))\n",
    "        return self.buffer_0[randint], self.buffer_1[randint], self.buffer_2[randint], self.buffer_3[randint], self.buffer_4[randint]\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## DQN Agent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [],
   "source": [
    "#################Simple DQN Agent########################################\n",
    "class DQNAgent():\n",
    "    def __init__(self, NN: object, NN_args: tuple = (), \n",
    "                 num_envs: int = 1, buffer_size: int = 800, \n",
    "                 lr: float = 0.0005, discount: float = 0.8, tau: float = 0.01,\n",
    "                 lam = 10):\n",
    "        #self.qnet = torch.load(\"dqn80x80.h5\")\n",
    "        self.qnet = NN(*NN_args)\n",
    "        \n",
    "        self.qnet_target = copy.deepcopy(self.qnet)\n",
    "        for param in self.qnet_target.parameters():\n",
    "            param.requires_grad = False\n",
    "    \n",
    "        self.qnet_optim = torch.optim.Adam( self.qnet.parameters(), lr=lr) #set learning rate\n",
    "        self.discount_factor = torch.Tensor([discount]).to(DEFAULT_DEVICE) # set discount factor\n",
    "        self.MSELoss_function = torch.nn.MSELoss()\n",
    "        self.replay_buffer = ReplayBuffer(buffer_size) #set size of replay buffer.\n",
    "        self.old_buffer = ReplayBuffer(300)\n",
    "        \n",
    "        self.lr = lr\n",
    "        self.target_update_interval = 500 #set for target update interval for hard target network updates\n",
    "        self.update_count= 0 #internal working variable. Don't change\n",
    "        self.tau = tau # set tau for soft target network updates\n",
    "        self.num_envs = num_envs\n",
    "        \n",
    "        self.ewc_counter = 0 #flag keep track of fisher matrix computations.\n",
    "        self.lam = torch.Tensor([lam]).to(DEFAULT_DEVICE)\n",
    "        self.ewc_on = False\n",
    "        self.fisher_recompute_interval = 3000\n",
    "        \n",
    "    def add_to_buffer(self, data):\n",
    "        self.replay_buffer.add_to_buffer(data)\n",
    "    \n",
    "    def load(self, path):\n",
    "        self.qnet = torch.load(path)\n",
    "        self.qnet_target = torch.load(path)\n",
    "        self.qnet_optim = torch.optim.Adam(self.qnet.parameters(), lr=self.lr)\n",
    "        \n",
    "    #computing diagonal of fisher matrix\n",
    "    def compute_fisher_diagonal(self, data):\n",
    "        t0=time.perf_counter()\n",
    "        print(\"Computing Fisher diagonal...\")\n",
    "        self.params = [p for p in agent.qnet.parameters()]\n",
    "        self.theta_star = [p.data for p in copy.deepcopy(self.params)]\n",
    "        matrix = [p.data*0 for p in copy.deepcopy(self.params)]\n",
    "        \n",
    "        for st in data:\n",
    "            agent.qnet.zero_grad()\n",
    "            output = agent.qnet(st.unsqueeze(0))\n",
    "            label = output.max(dim=1)[1]\n",
    "            lsm = torch.nn.functional.log_softmax(output, dim=1)\n",
    "            loss = torch.nn.functional.nll_loss(lsm, label)\n",
    "            temp = torch.autograd.grad(loss,self.params)\n",
    "    \n",
    "            for n in range(len(matrix)):\n",
    "                matrix[n]+=temp[n]**2\n",
    "\n",
    "        for n in range(len(matrix)):\n",
    "            matrix[n]/=data.shape[0]\n",
    "        self.fisher = matrix\n",
    "        t1=time.perf_counter()\n",
    "        print(\"Computing Fisher diagonal completed:\", t1-t0)\n",
    "\n",
    "    #Computing EWC loss using diagonal of fisher matrix  \n",
    "    #Based on https://arxiv.org/abs/1612.00796\n",
    "    def ewc_loss(self):\n",
    "        loss = 0\n",
    "        for n in range(len(self.fisher)):\n",
    "            loss+=(self.fisher[n]*(self.params[n]-self.theta_star[n])**2).sum()\n",
    "        return loss*self.lam\n",
    "    \n",
    "    def train(self):\n",
    "        self.qnet.train()\n",
    "        torch.set_grad_enabled(True)\n",
    "        \n",
    "    def evaluate(self):\n",
    "        self.qnet.eval()\n",
    "        torch.set_grad_enabled(False)\n",
    "        \n",
    "    #Hard update target network\n",
    "    def target_update(self,network,target_network):\n",
    "        for net_params, target_net_params in zip(network.parameters(), target_network.parameters()):\n",
    "            target_net_params.data.copy_(net_params.data)\n",
    "     \n",
    "    #Soft update target network\n",
    "    def soft_target_update(self,network,target_network):\n",
    "        for net_params, target_net_params in zip(network.parameters(), target_network.parameters()):\n",
    "            target_net_params.data.copy_(net_params.data*self.tau + (1-self.tau)*target_net_params)\n",
    "    \n",
    "    def epsilon_greedy_action(self, env, state, epsilon):\n",
    "        if np.random.uniform(0, 1) < epsilon:\n",
    "                return env.random_action()  # choose random action\n",
    "        else:                \n",
    "            return torch.argmax(self.qnet(state), dim=1)  # choose greedy action\n",
    "    \n",
    "    #update Q Network by calculating gradient of neural network loss\n",
    "    def update_Q_Network(self, state, next_state, action, reward, terminals):\n",
    "        qsa = torch.gather(self.qnet(state), dim=1, index=action.unsqueeze(-1)).squeeze()\n",
    "        qsa_next_action = self.qnet_target(next_state)\n",
    "        qsa_next_action = torch.max(qsa_next_action, dim=1)[0]\n",
    "        not_terminals = ~terminals\n",
    "        qsa_next_target = reward + not_terminals * self.discount_factor * qsa_next_action\n",
    "        \n",
    "        q_network_loss = self.MSELoss_function(qsa, qsa_next_target.detach())\n",
    "        #EWC loss\n",
    "        if self.ewc_on:\n",
    "            q_network_loss+=self.ewc_loss()\n",
    "\n",
    "        #Gradient descent\n",
    "        self.qnet_optim.zero_grad()\n",
    "        q_network_loss.backward()\n",
    "        self.qnet_optim.step()\n",
    "     \n",
    "    #call this to update Q network (train) and then make hard update of target network\n",
    "    def hard_update(self, update_rate):\n",
    "        for _ in range(update_rate):\n",
    "            states, next_states, actions, rewards, terminals = self.replay_buffer.sample(self.num_envs//3)\n",
    "            self.update_Q_Network(states, next_states, actions, rewards, terminals)\n",
    "            self.update_count+=1\n",
    "            if self.update_count==self.target_update_interval:\n",
    "                self.target_update(self.qnet, self.qnet_target)\n",
    "                self.update_count=0\n",
    "                \n",
    "    #call this to update Q network (train) and then make soft update of target network\n",
    "    def update(self, update_rate, batch_size = 100):\n",
    "        if self.ewc_on:\n",
    "            if self.ewc_counter%(self.fisher_recompute_interval*update_rate)==0:\n",
    "                data = self.replay_buffer.sample_superbatch(3)[0]\n",
    "                self.compute_fisher_diagonal(data)\n",
    "                self.ewc_counter=0\n",
    "            self.ewc_counter+=1\n",
    "           \n",
    "        for _ in range(update_rate):\n",
    "            states, next_states, actions, rewards, terminals = self.replay_buffer.sample(batch_size)\n",
    "            self.update_Q_Network(states, next_states, actions, rewards, terminals)\n",
    "            self.soft_target_update(self.qnet, self.qnet_target)\n",
    "\n",
    "###############Simple DQN Agent######################################################            \n",
    "\n",
    "#################Double DQN Agent smooth##############################################\n",
    "#Based on https://arxiv.org/abs/1509.06461v3\n",
    "class DDQNAgent_smooth(DQNAgent):\n",
    "    def __init__(self, NN: object, NN_args: tuple = (), \n",
    "                 num_envs: int = 1, buffer_size: int = 800,\n",
    "                 lr: float = 0.0005, discount: float = 0.8, tau: float = 0.01):\n",
    "        super().__init__(NN, NN_args, num_envs, buffer_size, lr, discount, tau)\n",
    "    \n",
    "    #update Q Network by calculating gradient of neural network loss\n",
    "    def update_Q_Network(self, state, next_state, action, reward, terminals):\n",
    "        qsa = torch.gather(self.qnet(state), dim=1, index=action.unsqueeze(-1)).squeeze()\n",
    "        q_target_next_state_a = self.qnet_target(next_state)\n",
    "        q_target_next_state_max_a = torch.argmax(q_target_next_state_a, dim=1)\n",
    "        q_next_state_a = torch.gather(self.qnet(next_state), dim=1, index=q_target_next_state_max_a.unsqueeze(-1)).squeeze()\n",
    "        not_terminals = ~terminals\n",
    "        qsa_next_target = reward + not_terminals * self.discount_factor * q_next_state_a\n",
    "        \n",
    "        q_network_loss = self.MSELoss_function(qsa, qsa_next_target.detach())\n",
    "        if self.ewc_on:\n",
    "            q_network_loss+=self.ewc_loss()\n",
    "            \n",
    "        self.qnet_optim.zero_grad()\n",
    "        q_network_loss.backward()\n",
    "        self.qnet_optim.step()\n",
    "        \n",
    "            \n",
    "#################Double DQN Agent smooth##################################\n",
    "\n",
    "#################Double DQN Agent########################################\n",
    "#Code discontinued. Will not be updated.\n",
    "#Based on https://arxiv.org/abs/1509.06461v1\n",
    "class DDQNAgent(DQNAgent):\n",
    "    def __init__(self, NN: object, NN_args: tuple = (), \n",
    "                 num_envs: int = 1, buffer_size: int = 800,\n",
    "                 lr: float = 0.0005, discount: float = 0.8):\n",
    "        #self.qnet = torch.load(\"dqn80x80.h5\")\n",
    "        self.Q_A = NN(*NN_args)\n",
    "        self.Q_B = NN(*NN_args)\n",
    "        self.Q_A_optim = torch.optim.Adam( self.Q_A.parameters(), lr=lr) #set learning rate\n",
    "        self.Q_B_optim = torch.optim.Adam( self.Q_B.parameters(), lr=lr) #set learning rate\n",
    "        self.discount_factor = torch.Tensor([discount]).to(DEFAULT_DEVICE) # set discount factor\n",
    "        self.MSELoss_function = torch.nn.MSELoss()\n",
    "        self.replay_buffer = ReplayBuffer(buffer_size) #set size of replay buffer.\n",
    "        self.num_envs = num_envs\n",
    "        pass\n",
    "    \n",
    "    def train(self):\n",
    "        self.Q_A.train()\n",
    "        self.Q_A.train()\n",
    "        torch.set_grad_enabled(True)\n",
    "        \n",
    "    def evaluate(self):\n",
    "        self.Q_A.eval()\n",
    "        self.Q_B.eval()\n",
    "        torch.set_grad_enabled(False)\n",
    "    \n",
    "    def epsilon_greedy_action(self, state, epsilon):\n",
    "        if np.random.uniform(0, 1) < epsilon:\n",
    "                return env.random_action()  # choose random action\n",
    "        else:                \n",
    "            return torch.argmax(self.Q_A(state), dim=1)  # choose greedy action\n",
    "    \n",
    "    #update Q Network by calculating gradient of neural network loss\n",
    "    def update_Q_A_Network(self, state, next_state, action, reward, terminals):\n",
    "        QA_s_a = torch.gather(self.Q_A(state), dim=1, index=action.unsqueeze(-1)).squeeze()\n",
    "        QA_sn_a = self.Q_A(next_state)\n",
    "        QA_sn_a_max = torch.argmax(QA_sn_a, dim=1)\n",
    "        QB_sn_a = torch.gather(self.Q_B(next_state), dim=1, index=QA_sn_a_max.unsqueeze(-1)).squeeze()\n",
    "        not_terminals = ~terminals\n",
    "        QA_s_a_target = reward + not_terminals * self.discount_factor * QB_sn_a\n",
    "        q_network_loss = self.MSELoss_function(QA_s_a, QA_s_a_target.detach())\n",
    "        self.Q_A_optim.zero_grad()\n",
    "        q_network_loss.backward()\n",
    "        self.Q_A_optim.step()\n",
    "        \n",
    "    def update_Q_B_Network(self, state, next_state, action, reward, terminals):\n",
    "        QB_s_a = torch.gather(self.Q_B(state), dim=1, index=action.unsqueeze(-1)).squeeze()\n",
    "        QB_sn_a = self.Q_B(next_state)\n",
    "        QB_sn_a_max = torch.argmax(QB_sn_a, dim=1)\n",
    "        QA_sn_a = torch.gather(self.Q_A(next_state), dim=1, index=QB_sn_a_max.unsqueeze(-1)).squeeze()\n",
    "        not_terminals = ~terminals\n",
    "        QB_s_a_target = reward + not_terminals * self.discount_factor * QA_sn_a\n",
    "        q_network_loss = self.MSELoss_function(QB_s_a, QB_s_a_target.detach())\n",
    "\n",
    "        self.Q_B_optim.zero_grad()\n",
    "        q_network_loss.backward()\n",
    "        self.Q_B_optim.step()\n",
    "        \n",
    "    #call this to update Q network (train) and then make soft update of target network\n",
    "    def update(self, update_rate, batch_size):\n",
    "        for _ in range(update_rate):\n",
    "            states, next_states, actions, rewards, terminals = self.replay_buffer.sample(batch_size)\n",
    "            if np.random.uniform()<0.5:\n",
    "                self.update_Q_A_Network(states, next_states, actions, rewards, terminals)\n",
    "            else:\n",
    "                self.update_Q_B_Network(states, next_states, actions, rewards, terminals)\n",
    "#################Double DQN Agent##############################################"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Defining Some Neural Networks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [],
   "source": [
    "# defining a fully connected neural network\n",
    "def FNN_1(shape, hidden_dim, action_dim):\n",
    "    flat_shape = np.product(shape) #length of the flattened state\n",
    "    model = torch.nn.Sequential(\n",
    "        torch.nn.Flatten(),\n",
    "        torch.nn.Linear(flat_shape,hidden_dim),\n",
    "        #torch.nn.Dropout(0.5),\n",
    "        torch.nn.ReLU(),\n",
    "        torch.nn.Linear(hidden_dim,hidden_dim),\n",
    "        #torch.nn.Dropout(0.5),\n",
    "        torch.nn.ReLU(),\n",
    "        torch.nn.Linear(hidden_dim, action_dim),\n",
    "         ).to(DEFAULT_DEVICE)\n",
    "    return model\n",
    "\n",
    "def CNN_1(): #A good model for SingleSnake\n",
    "    model = torch.nn.Sequential(\n",
    "        torch.nn.Conv2d(1, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1)),\n",
    "        torch.nn.ReLU(),\n",
    "        torch.nn.Conv2d(32, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1)),\n",
    "        torch.nn.Dropout(0.1),\n",
    "        torch.nn.ReLU(),\n",
    "        torch.nn.Conv2d(64, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1)),\n",
    "        torch.nn.Dropout(0.2),\n",
    "        torch.nn.ReLU(),\n",
    "        torch.nn.AdaptiveMaxPool2d((1,1)),\n",
    "        torch.nn.Flatten(),\n",
    "        torch.nn.Linear(128, 128),\n",
    "        torch.nn.Dropout(0.5),\n",
    "        torch.nn.ReLU(),\n",
    "        torch.nn.Linear(128, 4),\n",
    "        ).to(DEFAULT_DEVICE)\n",
    "    return model\n",
    "\n",
    "def CNN_2():\n",
    "    model = torch.nn.Sequential(\n",
    "        torch.nn.Conv2d(1, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1)),\n",
    "        torch.nn.ReLU(),\n",
    "        torch.nn.Conv2d(32, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1)),\n",
    "        torch.nn.Dropout(0.1),\n",
    "        torch.nn.ReLU(),\n",
    "        torch.nn.Conv2d(64, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1)),\n",
    "        torch.nn.Dropout(0.2),\n",
    "        torch.nn.ReLU(),\n",
    "        torch.nn.AdaptiveMaxPool2d((1,1)),\n",
    "        torch.nn.Flatten(),\n",
    "        torch.nn.Linear(128, 128),\n",
    "        torch.nn.Dropout(0.5),\n",
    "        torch.nn.ReLU(),\n",
    "        torch.nn.Linear(128, 128),\n",
    "        torch.nn.Dropout(0.5),\n",
    "        torch.nn.ReLU(),\n",
    "        torch.nn.Linear(128, 4),\n",
    "        ).to(DEFAULT_DEVICE)\n",
    "    return model\n",
    "\n",
    "def CNN_3():\n",
    "    model = torch.nn.Sequential(\n",
    "        torch.nn.Conv2d(1, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1)),\n",
    "        torch.nn.ReLU(),\n",
    "        torch.nn.Conv2d(32, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1)),\n",
    "        torch.nn.AdaptiveMaxPool2d((1,1)),\n",
    "        torch.nn.Flatten(),\n",
    "        torch.nn.Linear(64, 128),\n",
    "        torch.nn.Dropout(0.4),\n",
    "        torch.nn.ReLU(),\n",
    "        torch.nn.Linear(128, 4),\n",
    "        ).to(DEFAULT_DEVICE)\n",
    "    return model\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Initializing Environment and Agent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sequential(\n",
      "  (0): Conv2d(1, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "  (1): ReLU()\n",
      "  (2): Conv2d(32, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "  (3): Dropout(p=0.1, inplace=False)\n",
      "  (4): ReLU()\n",
      "  (5): Conv2d(64, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "  (6): Dropout(p=0.2, inplace=False)\n",
      "  (7): ReLU()\n",
      "  (8): AdaptiveMaxPool2d(output_size=(1, 1))\n",
      "  (9): Flatten()\n",
      "  (10): Linear(in_features=128, out_features=128, bias=True)\n",
      "  (11): Dropout(p=0.5, inplace=False)\n",
      "  (12): ReLU()\n",
      "  (13): Linear(in_features=128, out_features=4, bias=True)\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "num_envs=1300\n",
    "test_num_envs=100\n",
    "\n",
    "#Effective buffer_size = buffer_size*num_envs\n",
    "agent=DDQNAgent_smooth(NN = CNN_1, #NN_args = (state_dim, 512, action_dim),\n",
    "                       num_envs = num_envs, buffer_size = 600, lr = 0.0005,\n",
    "                       discount = 0.8, tau =0.1)\n",
    "\n",
    "temp_env = SingleSnake(num_envs=100, size=10, observation_mode='one_channel', device= DEFAULT_DEVICE)\n",
    "env = SimpleGridworld(num_envs=num_envs, size=10, observation_mode='one_channel', device= DEFAULT_DEVICE)\n",
    "test_env = SimpleGridworld(num_envs=test_num_envs, size=10, observation_mode='one_channel', device= DEFAULT_DEVICE, auto_reset=False)\n",
    "test_env_1 = SingleSnake(num_envs=test_num_envs, size=10, observation_mode='one_channel', device= DEFAULT_DEVICE, auto_reset=False)\n",
    "\n",
    "state = env.reset()\n",
    "state_dim = state.shape[1:]\n",
    "action_dim = 4\n",
    "agent.load(\"models/best_model.h5\")\n",
    "\n",
    "agent.train()\n",
    "print(agent.qnet)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-96-2eb11e30a824>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     51\u001b[0m     \u001b[1;31m##############Learning######################\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     52\u001b[0m     \u001b[0maction\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0magent\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mepsilon_greedy_action\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0menv\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mstate\u001b[0m \u001b[1;33m,\u001b[0m \u001b[0mepsilon\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 53\u001b[1;33m     \u001b[0mnext_state\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mreward\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mterminal\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0m_\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0menv\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mstep\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0maction\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     54\u001b[0m     \u001b[0magent\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0madd_to_buffer\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mstate\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mnext_state\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0maction\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mreward\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mterminal\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     55\u001b[0m     \u001b[0magent\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mupdate\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mupdate_rate\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m10\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m400\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\OneDrive - University of Bath\\Reinforcement Learning\\Fast Snake\\wurm\\envs\\simple_gridworld.py\u001b[0m in \u001b[0;36mstep\u001b[1;34m(self, actions)\u001b[0m\n\u001b[0;32m    221\u001b[0m             \u001b[0mfood_addition_env_indices\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mfood_removal\u001b[0m \u001b[1;33m*\u001b[0m \u001b[1;33m-\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mview\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mnum_envs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m-\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msum\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdim\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;33m-\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mbool\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    222\u001b[0m             \u001b[0madd_food_envs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0menvs\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mfood_addition_env_indices\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m:\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m:\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m:\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 223\u001b[1;33m             \u001b[0mfood_addition\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_get_food_addition\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0madd_food_envs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    224\u001b[0m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0menvs\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mfood_addition_env_indices\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mFOOD_CHANNEL\u001b[0m\u001b[1;33m:\u001b[0m\u001b[0mFOOD_CHANNEL\u001b[0m\u001b[1;33m+\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m:\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m:\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m+=\u001b[0m \u001b[0mfood_addition\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    225\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mverbose\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\OneDrive - University of Bath\\Reinforcement Learning\\Fast Snake\\wurm\\envs\\simple_gridworld.py\u001b[0m in \u001b[0;36m_get_food_addition\u001b[1;34m(self, envs)\u001b[0m\n\u001b[0;32m    266\u001b[0m         \u001b[0mavailable_locations\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m:\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m:\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m-\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;36m0\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    267\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 268\u001b[1;33m         \u001b[0mfood_indices\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mdrop_duplicates\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtorch\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mnonzero\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mavailable_locations\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m0\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    269\u001b[0m         food_addition = torch.sparse_coo_tensor(\n\u001b[0;32m    270\u001b[0m             food_indices.t(),  torch.ones(len(food_indices)), available_locations.shape, device=self.device)\n",
      "\u001b[1;32m~\\OneDrive - University of Bath\\Reinforcement Learning\\Fast Snake\\wurm\\utils.py\u001b[0m in \u001b[0;36mdrop_duplicates\u001b[1;34m(tensor, column, random)\u001b[0m\n\u001b[0;32m    227\u001b[0m     \u001b[0mindices\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0munique1d\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0muniq\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mreturn_index\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mTrue\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    228\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 229\u001b[1;33m     \u001b[0munique\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtensor\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mindices\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mlong\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    230\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    231\u001b[0m     \u001b[1;32mreturn\u001b[0m \u001b[0munique\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "#%%time\n",
    "render=False\n",
    "save_model = False\n",
    "number_of_steps = 100000\n",
    "epsilon = 1.0\n",
    "####Code to compute total reward####\n",
    "\n",
    "total_reward = torch.zeros(num_envs).to(DEFAULT_DEVICE)\n",
    "step_list=[]\n",
    "fc_list=[]\n",
    "fc_list_1=[] #food collected\n",
    "best_fc = 0\n",
    "####Code to compute total reward####\n",
    "\n",
    "agent.load(\"models/best_model.h5\")\n",
    "\n",
    "agent.evaluate()\n",
    "agent.replay_buffer.clear_buffer()\n",
    "\n",
    "state = temp_env.reset()\n",
    "\n",
    "##########Filling the buffer###############################\n",
    "for i in range(3):\n",
    "    action = agent.epsilon_greedy_action(temp_env, state , 0.0) \n",
    "    next_state, reward, terminal, _ = temp_env.step(action)\n",
    "    agent.add_to_buffer((state,next_state,action,reward,terminal))\n",
    "    state = next_state\n",
    "\n",
    "agent.train()\n",
    "#agent.qnet.eval()\n",
    "agent.ewc_on=True\n",
    "data = agent.replay_buffer.sample_superbatch(1)[0]\n",
    "agent.compute_fisher_diagonal(data)\n",
    "del data\n",
    "agent.lam = 400\n",
    "agent.fisher_recompute_interval = 100000\n",
    "agent.ewc_counter+=1\n",
    "agent.replay_buffer.clear_buffer()\n",
    "\n",
    "agent.train()\n",
    "state = env.reset()\n",
    "for i in range(30):\n",
    "    action = agent.epsilon_greedy_action(env, state , 1.0) \n",
    "    next_state, reward, terminal, _ = env.step(action)\n",
    "    agent.add_to_buffer((state,next_state,action,reward,terminal))\n",
    "    state = next_state\n",
    "    \n",
    "state = env.reset()\n",
    "#Learning\n",
    "for i in range(1,number_of_steps):\n",
    "    ##############Learning######################\n",
    "    action = agent.epsilon_greedy_action(env, state , epsilon) \n",
    "    next_state, reward, terminal, _ = env.step(action)\n",
    "    agent.add_to_buffer((state,next_state,action,reward,terminal))\n",
    "    agent.update(update_rate=10, batch_size=400)\n",
    "    state = next_state\n",
    "    \n",
    "\n",
    "    ##########Changing Epsilon###################\n",
    "    if i==1000:\n",
    "        epsilon = 0.1\n",
    "    elif i==3000:\n",
    "        epsilon = 0.01\n",
    "    elif i==5000:\n",
    "        epsilon = 0.001\n",
    "    elif i==10000:\n",
    "        epsilon = 0.0001\n",
    "    elif i==15000:\n",
    "        epsilon = 0.00001\n",
    "    elif i==15000:\n",
    "        epsilon = 0.000001\n",
    "    \n",
    "    ###################Rendering###################\n",
    "    if render:\n",
    "        env.render()\n",
    "\n",
    "    #############Validation############################\n",
    "    if (i%100==0):\n",
    "        agent.evaluate()                        \n",
    "        t_state = test_env.reset()\n",
    "        t_state_1 = test_env_1.reset()\n",
    "        fc_sum = torch.zeros((test_num_envs,)).float().to(DEFAULT_DEVICE) #foot collected\n",
    "        fc_sum_1 = torch.zeros((test_num_envs,)).float().to(DEFAULT_DEVICE) #foot collected\n",
    "        #hit_terminal = torch.zeros((test_num_envs,)).bool().to(DEFAULT_DEVICE)\n",
    "\n",
    "        for steps in range(1000): #max steps\n",
    "            t_action = agent.epsilon_greedy_action(test_env, t_state , 0.0)\n",
    "            t_action_1 = agent.epsilon_greedy_action(test_env_1, t_state_1 , 0.0)\n",
    "            t_next_state, t_reward, t_terminal, _ = test_env.step(t_action)\n",
    "            t_next_state_1, t_reward_1, t_terminal_1, _ = test_env_1.step(t_action_1)\n",
    "            #anything with a positive reward is considered as food.\n",
    "            fc_sum+=(t_reward>0).float()\n",
    "            fc_sum_1+=(t_reward_1>0).float()\n",
    "            #hit_terminal |= t_terminal\n",
    "            t_state = t_next_state\n",
    "            t_state_1 = t_next_state_1\n",
    "            if t_terminal_1.all() and t_terminal.all():\n",
    "                break\n",
    "\n",
    "        t_sum = fc_sum.cpu().numpy()\n",
    "        t_mean = np.mean(t_sum)\n",
    "        t_sum_1 = fc_sum_1.cpu().numpy()\n",
    "        t_mean_1 = np.mean(t_sum_1)\n",
    "        print('Step:', i)\n",
    "        print(\"Episode Completed:\", t_terminal.sum().cpu().numpy(), \"/\", test_num_envs)\n",
    "        print(\"Mean, Median, Max, Min, std:\", \n",
    "              t_mean, \n",
    "              np.median(t_sum),\n",
    "              np.max(t_sum),\n",
    "              np.min(t_sum),\n",
    "              np.std(t_sum))\n",
    "        print(\"Episode Completed:\", t_terminal_1.sum().cpu().numpy(), \"/\", test_num_envs)\n",
    "        print(\"Mean, Median, Max, Min, std:\", \n",
    "              t_mean_1, \n",
    "              np.median(t_sum_1),\n",
    "              np.max(t_sum_1),\n",
    "              np.min(t_sum_1),\n",
    "              np.std(t_sum_1))\n",
    "        \n",
    "        fc_list.append(t_mean)\n",
    "        fc_list_1.append(t_mean_1)\n",
    "        step_list.append(i)\n",
    "        plt.plot(step_list, fc_list)\n",
    "        plt.show()\n",
    "        plt.plot(step_list, fc_list_1)\n",
    "        plt.show()\n",
    "        agent.train()\n",
    "        #agent.qnet.eval()\n",
    "        clear_output(wait=True)\n",
    "        \n",
    "        \n",
    "#########Closing renderer if open########################    \n",
    "if render:    \n",
    "    env.close()\n",
    "\n",
    "##########Saving model##########################   \n",
    "if save_model:\n",
    "    model = torch.load(\"best_model.h5\")\n",
    "    with open('models/best_model.pickle', 'wb') as f:\n",
    "        pickle.dump((model, step_list,fc_list), f)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Storing Data of best model and associated runtime data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'DDQNAgent_smooth' object has no attribute 'loss'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-32-a8685496ec97>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0magent\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mloss\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m: 'DDQNAgent_smooth' object has no attribute 'loss'"
     ]
    }
   ],
   "source": [
    "agent."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "#Visualizing reward\n",
    "plt.plot(step_list, fc_list)\n",
    "plt.show()\n",
    "\n",
    "#agent.qnet = torch.load(\"models/bestest_model(1).h5\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#Visualizing reward\n",
    "plt.plot(step_list, fc_list)\n",
    "plt.show()\n",
    "\n",
    "#Store data about the best model as a pickle file\n",
    "import pickle\n",
    "model = torch.load(\"models/best_model.h5\")\n",
    "with open('models/cnn_256_avg_822.pickle', 'xb') as f:\n",
    "    pickle.dump((model, step_list,fc_list), f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#to load the saved model\n",
    "with open('models/bestest_model.pickle', 'rb') as f:\n",
    "     data = pickle.load(f)\n",
    "\n",
    "model = data[0].to(DEFAULT_DEVICE)        \n",
    "agent.qnet= data[0]\n",
    "\n",
    "plt.plot(data[1], data[2])\n",
    "plt.show()\n",
    "print(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "agent.qnet = torch.load(\"models/bestest_model.h5\")\n",
    "print(agent.qnet)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Visualize and Record Gameplay"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "%%time\n",
    "env = SingleSnake(num_envs=1, size=10, observation_mode='one_channel', device= DEFAULT_DEVICE)\n",
    "agent.evaluate()\n",
    "PATH = os.getcwd()\n",
    "state = env.reset()\n",
    "for episode in range(100):\n",
    "    fc_sum = 0\n",
    "    recorder = VideoRecorder(env, path=PATH + f'/videos/snake_{episode}.mp4')\n",
    "    #env.render()\n",
    "    recorder.capture_frame()\n",
    "    time.sleep(0.2)\n",
    "    counter = 0\n",
    "    while(1):\n",
    "        counter+=1\n",
    "        action = agent.epsilon_greedy_action(env, state , 0.0)\n",
    "        next_state, reward, terminal, _ = env.step(action)\n",
    "        fc_sum+= (reward>0).cpu().numpy()\n",
    "        #env.render()\n",
    "        recorder.capture_frame()\n",
    "        #time.sleep(0.2)\n",
    "        state = next_state\n",
    "        if terminal.all() or counter==1000:\n",
    "            recorder.close()\n",
    "            break\n",
    "    print(\"Completed:\", terminal.any().cpu().numpy())\n",
    "    print('Episode:', episode, 'Food Collected:', fc_sum)\n",
    "\n",
    "#env.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "recorder.close()\n",
    "env.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Computing Average Return"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Completed: 1300\n",
      "Mean, Median, Max, Min, std: 23.303078 24.0 40.0 1.0 6.2513127\n"
     ]
    }
   ],
   "source": [
    "test_env = SingleSnake(num_envs=num_envs, size=10, observation_mode='one_channel', device= DEFAULT_DEVICE, auto_reset=False)\n",
    "agent.evaluate()\n",
    "\n",
    "                       \n",
    "t_state = test_env.reset()\n",
    "fc_sum = torch.zeros((num_envs,)).float().to(DEFAULT_DEVICE) #foot collected\n",
    "\n",
    "for steps in range(1000): #max steps\n",
    "    t_action = agent.epsilon_greedy_action(test_env, t_state , 0.0)\n",
    "    t_next_state, t_reward, t_terminal, _ = test_env.step(t_action)\n",
    "    #anything with a positive reward is considered as food.\n",
    "    fc_sum+=(t_reward>0).float()\n",
    "    t_state = t_next_state\n",
    "    if t_terminal.all():\n",
    "        break\n",
    "\n",
    "t_sum = fc_sum.cpu().numpy()\n",
    "t_mean = np.mean(t_sum)\n",
    "print(\"Completed:\", t_terminal.sum().cpu().numpy())\n",
    "print(\"Mean, Median, Max, Min, std:\", \n",
    "      t_mean, \n",
    "      np.median(t_sum),\n",
    "      np.max(t_sum),\n",
    "      np.min(t_sum),\n",
    "      np.std(t_sum))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
