{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from IPython.display import clear_output, display\n",
    "import torch\n",
    "import random\n",
    "import copy\n",
    "import time\n",
    "import os #to get current working directory\n",
    "import csv\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from wurm.envs import SingleSnake\n",
    "from wurm.envs import SimpleGridworld\n",
    "from gym.wrappers.monitoring.video_recorder import VideoRecorder\n",
    "\n",
    "DEFAULT_DEVICE = 'cuda' #set device"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Visualizing the neural network. Requires Tensorboard"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "from torch.utils.tensorboard import SummaryWriter\n",
    "writer = SummaryWriter()\n",
    "writer.add_graph(qnet, torch.Tensor(env.reset()))\n",
    "writer.close()\n",
    "%load_ext tensorboard\n",
    "%tensorboard --logdir=runs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Replay Buffer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import collections\n",
    "\n",
    "class ReplayBuffer():\n",
    "    def __init__(self, max_buffer_size: int):\n",
    "        #data must be of the form (state,next_state,action,reward,terminal)\n",
    "        self.buffer = collections.deque(maxlen=max_buffer_size)\n",
    "\n",
    "    def add_to_buffer(self, data):\n",
    "        #data must be of the form (state,next_state,action,reward,terminal)\n",
    "        self.buffer.append(data)\n",
    "    def clear_buffer(self):\n",
    "        self.buffer.clear()\n",
    "        \n",
    "    #Sample superbatches and sub sample parallel environments\n",
    "    def sample_subbatch(self,superbatch_length, subbatch_length):\n",
    "        states = []\n",
    "        next_states = []\n",
    "        actions = []\n",
    "        rewards = []\n",
    "        terminals = []\n",
    "        sub_length = self.buffer[0][0].shape[0]\n",
    "        for rand_int in np.random.randint(0, len(self.buffer), superbatch_length):\n",
    "            rand_int_1 = np.random.randint(0, sub_length, subbatch_length)\n",
    "            transition = self.buffer[rand_int]\n",
    "            states.append(transition[0][rand_int_1])\n",
    "            next_states.append(transition[1][rand_int_1])\n",
    "            actions.append(transition[2][rand_int_1])\n",
    "            rewards.append(transition[3][rand_int_1])\n",
    "            terminals.append(transition[4][rand_int_1])\n",
    "        return torch.cat(states), torch.cat(next_states), torch.cat(actions), torch.cat(rewards), torch.cat(terminals)\n",
    "\n",
    "    def sample_superbatch(self,superbatch_length):\n",
    "        states = []\n",
    "        next_states = []\n",
    "        actions = []\n",
    "        rewards = []\n",
    "        terminals = []\n",
    "        for rand_int in np.random.randint(0, len(self.buffer), superbatch_length):\n",
    "            transition = self.buffer[rand_int]\n",
    "            states.append(transition[0])\n",
    "            next_states.append(transition[1])\n",
    "            actions.append(transition[2])\n",
    "            rewards.append(transition[3])\n",
    "            terminals.append(transition[4])\n",
    "        return torch.cat(states), torch.cat(next_states), torch.cat(actions), torch.cat(rewards), torch.cat(terminals)\n",
    "    \n",
    "    #sample parallel environments of subbatch_length from a randomly selected buffer location.\n",
    "    def sample(self, subbatch_length):\n",
    "            rand_int = np.random.randint(0, len(self.buffer))\n",
    "            rand_int_1 = np.random.randint(0, len(self.buffer[0][0]), subbatch_length)\n",
    "            transition = self.buffer[rand_int]\n",
    "            states=transition[0][rand_int_1]\n",
    "            next_states=transition[1][rand_int_1]\n",
    "            actions=transition[2][rand_int_1]\n",
    "            rewards=transition[3][rand_int_1]\n",
    "            terminals=transition[4][rand_int_1]\n",
    "            return (states,next_states,actions,rewards,terminals)\n",
    "\n",
    "        \n",
    "#A buffer with lesser correlation between samples. Implemented with pytorch. \n",
    "#Presently not working properly. Not sure why.\n",
    "class BetterBuffer():\n",
    "    def __init__(self, max_envs: int = 1000):\n",
    "        #data must be of the form (state,next_state,action,reward,terminal)\n",
    "        self.buffer_0 = torch.empty(0).to(DEFAULT_DEVICE)\n",
    "        self.buffer_1 = torch.empty(0).to(DEFAULT_DEVICE)\n",
    "        self.buffer_2 = torch.empty(0).long().to(DEFAULT_DEVICE)\n",
    "        self.buffer_3 = torch.empty(0).to(DEFAULT_DEVICE)\n",
    "        self.buffer_4 = torch.empty(0).bool().to(DEFAULT_DEVICE)\n",
    "        self.max_length = max_envs\n",
    "        self.pointer = 0\n",
    "        self.full = False\n",
    "\n",
    "    def add_to_buffer(self, data):\n",
    "        #data must be of the form (state,next_state,action,reward,terminal)\n",
    "        if self.full == True:\n",
    "            if self.pointer==self.max_length:\n",
    "                self.pointer=0\n",
    "            self.buffer_0[self.pointer*num_envs:(self.pointer+1)*num_envs] = data[0]\n",
    "            self.buffer_1[self.pointer*num_envs:(self.pointer+1)*num_envs] = data[1]\n",
    "            self.buffer_2[self.pointer*num_envs:(self.pointer+1)*num_envs] = data[2]\n",
    "            self.buffer_3[self.pointer*num_envs:(self.pointer+1)*num_envs] = data[3]\n",
    "            self.buffer_4[self.pointer*num_envs:(self.pointer+1)*num_envs] = data[4]\n",
    "            self.pointer+=1\n",
    "        else:\n",
    "            self.buffer_0=torch.cat((self.buffer_0,data[0]))\n",
    "            self.buffer_1=torch.cat((self.buffer_1,data[1]))\n",
    "            self.buffer_2=torch.cat((self.buffer_2,data[2]))\n",
    "            self.buffer_3=torch.cat((self.buffer_3,data[3]))\n",
    "            self.buffer_4=torch.cat((self.buffer_4,data[4]))\n",
    "            self.pointer+=1\n",
    "            if self.pointer==self.max_length:\n",
    "                self.full=True\n",
    "        \n",
    "    def sample(self, batch_size):\n",
    "        if self.full == True:\n",
    "            randint = torch.randint(0, self.max_length*num_envs,(batch_size,))\n",
    "        else:\n",
    "            randint = torch.randint(0,self.pointer*num_envs, (batch_size,))\n",
    "        return self.buffer_0[randint], self.buffer_1[randint], self.buffer_2[randint], self.buffer_3[randint], self.buffer_4[randint]\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## DQN Agent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "#################Simple DQN Agent########################################\n",
    "class DQNAgent():\n",
    "    def __init__(self, NN: object, NN_args: tuple = (), \n",
    "                 num_envs: int = 1, buffer_size: int = 800, \n",
    "                 lr: float = 0.0005, discount: float = 0.8, tau: float = 0.01,\n",
    "                 lam = 10):\n",
    "        #self.qnet = torch.load(\"dqn80x80.h5\")\n",
    "        self.qnet = NN(*NN_args)\n",
    "        \n",
    "        self.qnet_target = copy.deepcopy(self.qnet)\n",
    "        for param in self.qnet_target.parameters():\n",
    "            param.requires_grad = False\n",
    "    \n",
    "        self.qnet_optim = torch.optim.Adam( self.qnet.parameters(), lr=lr) #set learning rate\n",
    "        self.discount_factor = torch.Tensor([discount]).to(DEFAULT_DEVICE) # set discount factor\n",
    "        self.MSELoss_function = torch.nn.MSELoss()\n",
    "        self.replay_buffer = ReplayBuffer(buffer_size) #set size of replay buffer.\n",
    "        \n",
    "        self.lr = lr\n",
    "        self.target_update_interval = 500 #set for target update interval for hard target network updates\n",
    "        self.update_count= 0 #internal working variable. Don't change\n",
    "        self.tau = tau # set tau for soft target network updates\n",
    "        self.num_envs = num_envs\n",
    "        \n",
    "        self.ewc_counter = 0 #flag keep track of fisher matrix computations.\n",
    "        self.lam = torch.Tensor([lam]).to(DEFAULT_DEVICE)\n",
    "        self.ewc_on = False\n",
    "        self.fisher_recompute_interval = 3000\n",
    "        \n",
    "    def add_to_buffer(self, data):\n",
    "        self.replay_buffer.add_to_buffer(data)\n",
    "    \n",
    "    def load(self, path):\n",
    "        self.qnet = torch.load(path, map_location = DEFAULT_DEVICE)\n",
    "        self.qnet_target = torch.load(path, map_location = DEFAULT_DEVICE)\n",
    "        self.qnet_optim = torch.optim.Adam(self.qnet.parameters(), lr=self.lr)\n",
    "        \n",
    "    #computing diagonal of fisher matrix\n",
    "    def compute_fisher_diagonal(self, data):\n",
    "        print(\"Computing Fisher diagonal...\")\n",
    "        self.params = [p for p in agent.qnet.parameters()]\n",
    "        self.theta_star = [p.data for p in copy.deepcopy(self.params)]\n",
    "        matrix = [p.data*0 for p in copy.deepcopy(self.params)]\n",
    "        \n",
    "        for st in data:\n",
    "            agent.qnet.zero_grad()\n",
    "            output = agent.qnet(st.unsqueeze(0))\n",
    "            label = output.max(dim=1)[1]\n",
    "            lsm = torch.nn.functional.log_softmax(output, dim=1)\n",
    "            loss = torch.nn.functional.nll_loss(lsm, label)\n",
    "            temp = torch.autograd.grad(loss,self.params)\n",
    "    \n",
    "            for n in range(len(matrix)):\n",
    "                matrix[n]+=temp[n]**2\n",
    "\n",
    "        for n in range(len(matrix)):\n",
    "            matrix[n]/=data.shape[0]\n",
    "        self.fisher = matrix\n",
    "        print(\"Computing Fisher diagonal completed.\")\n",
    "\n",
    "    #Computing EWC loss using diagonal of fisher matrix  \n",
    "    #Based on https://arxiv.org/abs/1612.00796\n",
    "    def ewc_loss(self):\n",
    "        loss = 0\n",
    "        for n in range(len(self.fisher)):\n",
    "            loss+=(self.fisher[n]*(self.params[n]-self.theta_star[n])**2).sum()\n",
    "        return loss*self.lam\n",
    "    \n",
    "    def train(self):\n",
    "        self.qnet.train()\n",
    "        torch.set_grad_enabled(True)\n",
    "        \n",
    "    def evaluate(self):\n",
    "        self.qnet.eval()\n",
    "        torch.set_grad_enabled(False)\n",
    "        \n",
    "    #Hard update target network\n",
    "    def target_update(self,network,target_network):\n",
    "        for net_params, target_net_params in zip(network.parameters(), target_network.parameters()):\n",
    "            target_net_params.data.copy_(net_params.data)\n",
    "     \n",
    "    #Soft update target network\n",
    "    def soft_target_update(self,network,target_network):\n",
    "        for net_params, target_net_params in zip(network.parameters(), target_network.parameters()):\n",
    "            target_net_params.data.copy_(net_params.data*self.tau + (1-self.tau)*target_net_params)\n",
    "    \n",
    "    def epsilon_greedy_action(self, env, state, epsilon):\n",
    "        if np.random.uniform(0, 1) < epsilon:\n",
    "                return env.random_action()  # choose random action\n",
    "        else:                \n",
    "            return torch.argmax(self.qnet(state), dim=1)  # choose greedy action\n",
    "    \n",
    "    #update Q Network by calculating gradient of neural network loss\n",
    "    def update_Q_Network(self, state, next_state, action, reward, terminals):\n",
    "        qsa = torch.gather(self.qnet(state), dim=1, index=action.unsqueeze(-1)).squeeze()\n",
    "        qsa_next_action = self.qnet_target(next_state)\n",
    "        qsa_next_action = torch.max(qsa_next_action, dim=1)[0]\n",
    "        not_terminals = ~terminals\n",
    "        qsa_next_target = reward + not_terminals * self.discount_factor * qsa_next_action\n",
    "        \n",
    "        q_network_loss = self.MSELoss_function(qsa, qsa_next_target.detach())\n",
    "        #EWC loss\n",
    "        if self.ewc_on:\n",
    "            q_network_loss+=self.ewc_loss()\n",
    "\n",
    "        #Gradient descent\n",
    "        self.qnet_optim.zero_grad()\n",
    "        q_network_loss.backward()\n",
    "        self.qnet_optim.step()\n",
    "     \n",
    "    #call this to update Q network (train) and then make hard update of target network\n",
    "    def hard_update(self, update_rate):\n",
    "        for _ in range(update_rate):\n",
    "            states, next_states, actions, rewards, terminals = self.replay_buffer.sample(self.num_envs//3)\n",
    "            self.update_Q_Network(states, next_states, actions, rewards, terminals)\n",
    "            self.update_count+=1\n",
    "            if self.update_count==self.target_update_interval:\n",
    "                self.target_update(self.qnet, self.qnet_target)\n",
    "                self.update_count=0\n",
    "                \n",
    "    #call this to update Q network (train) and then make soft update of target network\n",
    "    def update(self, update_rate, batch_size = 100):\n",
    "        if self.ewc_on:\n",
    "            if self.ewc_counter%(self.fisher_recompute_interval*update_rate)==0:\n",
    "                data = self.replay_buffer.sample_superbatch(3)[0]\n",
    "                self.compute_fisher_diagonal(data)\n",
    "                self.ewc_counter=0\n",
    "            self.ewc_counter+=1\n",
    "           \n",
    "        for _ in range(update_rate):\n",
    "            states, next_states, actions, rewards, terminals = self.replay_buffer.sample(batch_size)\n",
    "            self.update_Q_Network(states, next_states, actions, rewards, terminals)\n",
    "            self.soft_target_update(self.qnet, self.qnet_target)\n",
    "\n",
    "###############Simple DQN Agent######################################################            \n",
    "\n",
    "#################Double DQN Agent smooth##############################################\n",
    "#Based on https://arxiv.org/abs/1509.06461v3\n",
    "class DDQNAgent_smooth(DQNAgent):\n",
    "    def __init__(self, NN: object, NN_args: tuple = (), \n",
    "                 num_envs: int = 1, buffer_size: int = 800,\n",
    "                 lr: float = 0.0005, discount: float = 0.8, tau: float = 0.01):\n",
    "        super().__init__(NN, NN_args, num_envs, buffer_size, lr, discount, tau)\n",
    "    \n",
    "    #update Q Network by calculating gradient of neural network loss\n",
    "    def update_Q_Network(self, state, next_state, action, reward, terminals):\n",
    "        qsa = torch.gather(self.qnet(state), dim=1, index=action.unsqueeze(-1)).squeeze()\n",
    "        q_target_next_state_a = self.qnet_target(next_state)\n",
    "        q_target_next_state_max_a = torch.argmax(q_target_next_state_a, dim=1)\n",
    "        q_next_state_a = torch.gather(self.qnet(next_state), dim=1, index=q_target_next_state_max_a.unsqueeze(-1)).squeeze()\n",
    "        not_terminals = ~terminals\n",
    "        qsa_next_target = reward + not_terminals * self.discount_factor * q_next_state_a\n",
    "        \n",
    "        q_network_loss = self.MSELoss_function(qsa, qsa_next_target.detach())\n",
    "        if self.ewc_on:\n",
    "            q_network_loss+=self.ewc_loss()\n",
    "            \n",
    "        self.qnet_optim.zero_grad()\n",
    "        q_network_loss.backward()\n",
    "        self.qnet_optim.step()\n",
    "        \n",
    "            \n",
    "#################Double DQN Agent smooth##################################\n",
    "\n",
    "#################Double DQN Agent########################################\n",
    "#Code discontinued. Will not be updated.\n",
    "#Based on https://arxiv.org/abs/1509.06461v1\n",
    "class DDQNAgent(DQNAgent):\n",
    "    def __init__(self, NN: object, NN_args: tuple = (), \n",
    "                 num_envs: int = 1, buffer_size: int = 800,\n",
    "                 lr: float = 0.0005, discount: float = 0.8):\n",
    "        #self.qnet = torch.load(\"dqn80x80.h5\")\n",
    "        self.Q_A = NN(*NN_args)\n",
    "        self.Q_B = NN(*NN_args)\n",
    "        self.Q_A_optim = torch.optim.Adam( self.Q_A.parameters(), lr=lr) #set learning rate\n",
    "        self.Q_B_optim = torch.optim.Adam( self.Q_B.parameters(), lr=lr) #set learning rate\n",
    "        self.discount_factor = torch.Tensor([discount]).to(DEFAULT_DEVICE) # set discount factor\n",
    "        self.MSELoss_function = torch.nn.MSELoss()\n",
    "        self.replay_buffer = ReplayBuffer(buffer_size) #set size of replay buffer.\n",
    "        self.num_envs = num_envs\n",
    "        pass\n",
    "    \n",
    "    def train(self):\n",
    "        self.Q_A.train()\n",
    "        self.Q_A.train()\n",
    "        torch.set_grad_enabled(True)\n",
    "        \n",
    "    def evaluate(self):\n",
    "        self.Q_A.eval()\n",
    "        self.Q_B.eval()\n",
    "        torch.set_grad_enabled(False)\n",
    "    \n",
    "    def epsilon_greedy_action(self, state, epsilon):\n",
    "        if np.random.uniform(0, 1) < epsilon:\n",
    "                return env.random_action()  # choose random action\n",
    "        else:                \n",
    "            return torch.argmax(self.Q_A(state), dim=1)  # choose greedy action\n",
    "    \n",
    "    #update Q Network by calculating gradient of neural network loss\n",
    "    def update_Q_A_Network(self, state, next_state, action, reward, terminals):\n",
    "        QA_s_a = torch.gather(self.Q_A(state), dim=1, index=action.unsqueeze(-1)).squeeze()\n",
    "        QA_sn_a = self.Q_A(next_state)\n",
    "        QA_sn_a_max = torch.argmax(QA_sn_a, dim=1)\n",
    "        QB_sn_a = torch.gather(self.Q_B(next_state), dim=1, index=QA_sn_a_max.unsqueeze(-1)).squeeze()\n",
    "        not_terminals = ~terminals\n",
    "        QA_s_a_target = reward + not_terminals * self.discount_factor * QB_sn_a\n",
    "        q_network_loss = self.MSELoss_function(QA_s_a, QA_s_a_target.detach())\n",
    "        self.Q_A_optim.zero_grad()\n",
    "        q_network_loss.backward()\n",
    "        self.Q_A_optim.step()\n",
    "        \n",
    "    def update_Q_B_Network(self, state, next_state, action, reward, terminals):\n",
    "        QB_s_a = torch.gather(self.Q_B(state), dim=1, index=action.unsqueeze(-1)).squeeze()\n",
    "        QB_sn_a = self.Q_B(next_state)\n",
    "        QB_sn_a_max = torch.argmax(QB_sn_a, dim=1)\n",
    "        QA_sn_a = torch.gather(self.Q_A(next_state), dim=1, index=QB_sn_a_max.unsqueeze(-1)).squeeze()\n",
    "        not_terminals = ~terminals\n",
    "        QB_s_a_target = reward + not_terminals * self.discount_factor * QA_sn_a\n",
    "        q_network_loss = self.MSELoss_function(QB_s_a, QB_s_a_target.detach())\n",
    "\n",
    "        self.Q_B_optim.zero_grad()\n",
    "        q_network_loss.backward()\n",
    "        self.Q_B_optim.step()\n",
    "        \n",
    "    #call this to update Q network (train) and then make soft update of target network\n",
    "    def update(self, update_rate, batch_size):\n",
    "        for _ in range(update_rate):\n",
    "            states, next_states, actions, rewards, terminals = self.replay_buffer.sample(batch_size)\n",
    "            if np.random.uniform()<0.5:\n",
    "                self.update_Q_A_Network(states, next_states, actions, rewards, terminals)\n",
    "            else:\n",
    "                self.update_Q_B_Network(states, next_states, actions, rewards, terminals)\n",
    "#################Double DQN Agent##############################################"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Defining Some Neural Networks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# defining a fully connected neural network\n",
    "def FNN_1(shape, hidden_dim, action_dim):\n",
    "    flat_shape = np.product(shape) #length of the flattened state\n",
    "    model = torch.nn.Sequential(\n",
    "        torch.nn.Flatten(),\n",
    "        torch.nn.Linear(flat_shape,hidden_dim),\n",
    "        #torch.nn.Dropout(0.5),\n",
    "        torch.nn.ReLU(),\n",
    "        torch.nn.Linear(hidden_dim,hidden_dim),\n",
    "        #torch.nn.Dropout(0.5),\n",
    "        torch.nn.ReLU(),\n",
    "        torch.nn.Linear(hidden_dim, action_dim),\n",
    "         ).to(DEFAULT_DEVICE)\n",
    "    return model\n",
    "\n",
    "def CNN_1(): #A good model for SingleSnake\n",
    "    model = torch.nn.Sequential(\n",
    "        torch.nn.Conv2d(1, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1)),\n",
    "        torch.nn.ReLU(),\n",
    "        torch.nn.Conv2d(32, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1)),\n",
    "        torch.nn.Dropout(0.1),\n",
    "        torch.nn.ReLU(),\n",
    "        torch.nn.Conv2d(64, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1)),\n",
    "        torch.nn.Dropout(0.2),\n",
    "        torch.nn.ReLU(),\n",
    "        torch.nn.AdaptiveMaxPool2d((1,1)),\n",
    "        torch.nn.Flatten(),\n",
    "        torch.nn.Linear(128, 128),\n",
    "        torch.nn.Dropout(0.5),\n",
    "        torch.nn.ReLU(),\n",
    "        torch.nn.Linear(128, 4),\n",
    "        ).to(DEFAULT_DEVICE)\n",
    "    return model\n",
    "\n",
    "def CNN_2():\n",
    "    model = torch.nn.Sequential(\n",
    "        torch.nn.Conv2d(1, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1)),\n",
    "        torch.nn.ReLU(),\n",
    "        torch.nn.Conv2d(32, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1)),\n",
    "        torch.nn.Dropout(0.1),\n",
    "        torch.nn.ReLU(),\n",
    "        torch.nn.Conv2d(64, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1)),\n",
    "        torch.nn.Dropout(0.2),\n",
    "        torch.nn.ReLU(),\n",
    "        torch.nn.AdaptiveMaxPool2d((1,1)),\n",
    "        torch.nn.Flatten(),\n",
    "        torch.nn.Linear(128, 128),\n",
    "        torch.nn.Dropout(0.5),\n",
    "        torch.nn.ReLU(),\n",
    "        torch.nn.Linear(128, 128),\n",
    "        torch.nn.Dropout(0.5),\n",
    "        torch.nn.ReLU(),\n",
    "        torch.nn.Linear(128, 4),\n",
    "        ).to(DEFAULT_DEVICE)\n",
    "    return model\n",
    "\n",
    "def CNN_3(): #A good model for SingleSnake\n",
    "    model = torch.nn.Sequential(\n",
    "        torch.nn.Conv2d(1, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1)),\n",
    "        torch.nn.ReLU(),\n",
    "        torch.nn.Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1)),\n",
    "        torch.nn.Dropout(0.1),\n",
    "        torch.nn.ReLU(),\n",
    "        torch.nn.Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1)),\n",
    "        torch.nn.Dropout(0.1),\n",
    "        torch.nn.ReLU(),\n",
    "        torch.nn.Conv2d(64, 2, kernel_size=(1, 1), stride=(1, 1)),\n",
    "        torch.nn.Dropout(0.1),\n",
    "        torch.nn.ReLU(),\n",
    "        torch.nn.Flatten(),\n",
    "        torch.nn.Linear(200, 128),\n",
    "        torch.nn.Dropout(0.5),\n",
    "        torch.nn.ReLU(),\n",
    "        torch.nn.Linear(128, 4),\n",
    "        ).to(DEFAULT_DEVICE)\n",
    "    return model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Initializing Environment and Agent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sequential(\n",
      "  (0): Flatten()\n",
      "  (1): Linear(in_features=100, out_features=1024, bias=True)\n",
      "  (2): ReLU()\n",
      "  (3): Linear(in_features=1024, out_features=1024, bias=True)\n",
      "  (4): ReLU()\n",
      "  (5): Linear(in_features=1024, out_features=4, bias=True)\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "environment = 'SimpleGridworld'\n",
    "num_envs = 1300 #Number of parallel environments to simulate. Use small value for cpu (eg. 1)\n",
    "test_num_envs = 100\n",
    "discount = 0.99\n",
    "tau = 0.1\n",
    "lr = 0.0005\n",
    "env_size = 10\n",
    "buffer_size = 600\n",
    "\n",
    "if environment == 'SimpleGridworld':\n",
    "    env = SimpleGridworld(num_envs=num_envs, size=env_size, observation_mode='one_channel', device= DEFAULT_DEVICE)\n",
    "    test_env = SimpleGridworld(num_envs=test_num_envs, size=env_size, observation_mode='one_channel', device= DEFAULT_DEVICE, auto_reset=False)\n",
    "\n",
    "    state = env.reset()\n",
    "    state_dim = state.shape[1:]\n",
    "    action_dim = 4\n",
    "\n",
    "    #Effective buffer_size = buffer_size*num_envs\n",
    "    agent=DQNAgent(NN = FNN_1, NN_args = (state_dim, 1024, action_dim),\n",
    "                           num_envs = num_envs, buffer_size = buffer_size, lr = lr,\n",
    "                           discount = discount, tau = tau)\n",
    "\n",
    "\n",
    "elif environment == 'SingleSnake':\n",
    "    env = SingleSnake(num_envs=num_envs, size=env_size, observation_mode='one_channel', device= DEFAULT_DEVICE)\n",
    "    test_env = SingleSnake(num_envs=test_num_envs, size=env_size, observation_mode='one_channel', device= DEFAULT_DEVICE, auto_reset=False)\n",
    "\n",
    "    state = env.reset()\n",
    "    state_dim = state.shape[1:]\n",
    "    action_dim = 4\n",
    "\n",
    "    #Effective buffer_size = buffer_size*num_envs\n",
    "    agent=DDQNAgent_smooth(NN = FNN_1, NN_args = (state_dim, 1024, action_dim),\n",
    "                           num_envs = num_envs, buffer_size = buffer_size, lr = lr, discount = discount, tau = tau)\n",
    "\n",
    "else:\n",
    "    raise Exception(\"Invalid option\")\n",
    "\n",
    "#agent.load(\"models/best_model.h5\")\n",
    "agent.train()\n",
    "print(agent.qnet)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<timed exec>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n",
      "\u001b[1;32m~\\OneDrive - University of Bath\\Reinforcement Learning\\Fast Snake\\wurm\\envs\\single_snake.py\u001b[0m in \u001b[0;36mstep\u001b[1;34m(self, actions)\u001b[0m\n\u001b[0;32m    284\u001b[0m             head(self.envs) * (\n\u001b[0;32m    285\u001b[0m                 \u001b[0msnake_sizes\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mexpand\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mnum_envs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msize\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msize\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m+\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 286\u001b[1;33m                 \u001b[0mhead_food_overlap\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mexpand\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mnum_envs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msize\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msize\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    287\u001b[0m             )\n\u001b[0;32m    288\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "%%time\n",
    "number_of_steps = 100000\n",
    "epsilon = 1.0\n",
    "update_rate = 10\n",
    "batch_size = 400\n",
    "####Code to compute total reward####\n",
    "\n",
    "total_reward = torch.zeros(num_envs).to(DEFAULT_DEVICE)\n",
    "step_list=[]\n",
    "fc_list=[] #food collected\n",
    "data_list = []\n",
    "best_fc = 0\n",
    "####Code to compute total reward####\n",
    "\n",
    "state=env.reset()\n",
    "agent.train()\n",
    "#agent.qnet.eval()\n",
    "##########Filling the buffer###############################\n",
    "for i in range(30):\n",
    "    action = agent.epsilon_greedy_action(env, state , 1.0) \n",
    "    next_state, reward, terminal, _ = env.step(action)\n",
    "    agent.add_to_buffer((state,next_state,action,reward,terminal))\n",
    "    state = next_state\n",
    "\n",
    "\n",
    "#Learning\n",
    "for i in range(1,number_of_steps):\n",
    "    ##############Learning######################\n",
    "    action = agent.epsilon_greedy_action(env, state , epsilon) \n",
    "    next_state, reward, terminal, _ = env.step(action)\n",
    "    agent.add_to_buffer((state,next_state,action,reward,terminal))\n",
    "    agent.update(update_rate=update_rate, batch_size=batch_size)\n",
    "    state = next_state\n",
    "    \n",
    "    ##########EWC###############################\n",
    "    if i==-1: #When to turn on EWC\n",
    "        agent.ewc_on=True #Turning on EWC\n",
    "        agent.lam=400 #Setting scalar parameter in EWC loss function\n",
    "        agent.fisher_recompute_interval = 2000 #steps after which diagonal fisher matrix is recomputed\n",
    "    \n",
    "    ##########Changing Epsilon###################\n",
    "    if i==1000:\n",
    "        epsilon = 0.1\n",
    "    elif i==3000:\n",
    "        epsilon = 0.01\n",
    "    elif i==5000:\n",
    "        epsilon = 0.001\n",
    "    elif i==30000:\n",
    "        epsilon = 0.0001\n",
    "    elif i==150000:\n",
    "        epsilon = 0.00001\n",
    "    \n",
    "    #############Validation and data collection############################\n",
    "    if (i%100==0):\n",
    "        agent.evaluate()                        \n",
    "        t_state = test_env.reset()\n",
    "        fc_sum = torch.zeros((test_num_envs,)).float().to(DEFAULT_DEVICE) #foot collected\n",
    "        #hit_terminal = torch.zeros((test_num_envs,)).bool().to(DEFAULT_DEVICE)\n",
    "\n",
    "        for steps in range(1000): #max steps\n",
    "            t_action = agent.epsilon_greedy_action(test_env, t_state , 0.0)\n",
    "            t_next_state, t_reward, t_terminal, _ = test_env.step(t_action)\n",
    "            #anything with a positive reward is considered as food.\n",
    "            fc_sum+=(t_reward>0).float()\n",
    "            t_state = t_next_state\n",
    "            if t_terminal.all():\n",
    "                break\n",
    "\n",
    "        t_sum = fc_sum.cpu().numpy()\n",
    "        t_mean = np.mean(t_sum)\n",
    "        t_median = np.median(t_sum)\n",
    "        t_max = np.max(t_sum)\n",
    "        t_min = np.min(t_sum)\n",
    "        t_std = np.std(t_sum)\n",
    "        t_completed = t_terminal.sum().cpu().numpy()\n",
    "        print('Step:', i)\n",
    "        print(\"Episode Completed:\", t_completed, \"/\", test_num_envs)\n",
    "        print(\"Mean, Median, Max, Min, std:\", \n",
    "              t_mean, \n",
    "              t_median,\n",
    "              t_max,\n",
    "              t_min,\n",
    "              t_std)\n",
    "        fc_list.append(t_mean)\n",
    "        data_list.append((i, t_mean, t_median, t_min, t_max, t_std, t_sum))\n",
    "        step_list.append(i)\n",
    "        plt.plot(step_list, fc_list)\n",
    "        plt.show()\n",
    "        agent.train()\n",
    "        clear_output(wait=True)\n",
    "        if t_mean>best_fc:\n",
    "            best_fc = t_mean\n",
    "            torch.save(agent.qnet,\"current_best.h5\")\n",
    "        \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([-0.0100, -0.0100, -0.0100,  ..., -0.0100, -1.0100, -0.0100],\n",
      "       device='cuda:0')\n"
     ]
    }
   ],
   "source": [
    "print(reward)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Storing Data of best model and associated runtime data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "#Visualizing reward\n",
    "plt.plot(step_list, fc_list)\n",
    "plt.show()\n",
    "\n",
    "#file name without extension\n",
    "file_name = \"ddqn_fnn1_disc0.99_hl1024\"\n",
    "\n",
    "parameters = {\"environment\": environment,\n",
    "              \"env_size\": env_size,\n",
    "              \"num_envs\": num_envs, \n",
    "              \"discount\": discount, \n",
    "              \"tau\": tau, \n",
    "              \"lr\": lr,\n",
    "              \"update_rate\": update_rate,\n",
    "              \"batch_size\": batch_size,\n",
    "              \"device\": DEFAULT_DEVICE\n",
    "             }\n",
    "heading = [\"step\", \"mean\", \"median\", \"min\", \"max\", \"std\", \"raw data\"]\n",
    "\n",
    "#create folder if it doesn't exist\n",
    "if not os.path.exists('data'):\n",
    "    os.makedirs('data')\n",
    "\n",
    "with open(F\"data/{file_name}.csv\", 'xt') as file:\n",
    "    writer = csv.writer(file, lineterminator=\"\\n\")\n",
    "    writer.writerow([\"parameters:\"])\n",
    "    writer.writerow(parameters.keys())\n",
    "    writer.writerow(parameters.values())\n",
    "    writer.writerow([\"DATA:\"])\n",
    "    writer.writerow(heading)\n",
    "    for item in data_list:\n",
    "        writer.writerow(item[0:-1]+tuple(item[-1]))\n",
    "    \n",
    "    \n",
    "#file name without extension\n",
    "\n",
    "#Store data about the best model as a pickle file\n",
    "model = torch.load(\"current_best.h5\")\n",
    "model = model.to('cpu')\n",
    "torch.save(model, F\"data/{file_name}.h5\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Parameters:\n",
      "{'environment': 'SingleSnake', 'env_size': '10', 'num_envs': '1300', 'discount': '0.8', 'tau': '0.1', 'lr': '0.0005', 'update_rate': '10', 'batch_size': '400', 'device': 'cuda'}\n",
      "\n",
      "Model:\n",
      "Sequential(\n",
      "  (0): Conv2d(1, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "  (1): ReLU()\n",
      "  (2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "  (3): Dropout(p=0.1, inplace=False)\n",
      "  (4): ReLU()\n",
      "  (5): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "  (6): Dropout(p=0.1, inplace=False)\n",
      "  (7): ReLU()\n",
      "  (8): Conv2d(64, 2, kernel_size=(1, 1), stride=(1, 1))\n",
      "  (9): Dropout(p=0.1, inplace=False)\n",
      "  (10): ReLU()\n",
      "  (11): Flatten()\n",
      "  (12): Linear(in_features=200, out_features=128, bias=True)\n",
      "  (13): Dropout(p=0.5, inplace=False)\n",
      "  (14): ReLU()\n",
      "  (15): Linear(in_features=128, out_features=4, bias=True)\n",
      ")\n",
      "\n",
      "Mean collected food:\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "#file name to read\n",
    "file_name = \"ddqn_cnn3_disc0.8_dropout\"\n",
    "\n",
    "parameters = {}\n",
    "heading = [\"step\", \"mean\", \"median\", \"min\", \"max\", \"std\", \"raw data\"]\n",
    "\n",
    "with open(F\"data/{file_name}.csv\", 'rt') as file:\n",
    "    reader = csv.reader(file)\n",
    "    data = [row for row in reader]\n",
    "    for key,value in zip(data[1],data[2]):\n",
    "        parameters[key] = value\n",
    "    data_list = []\n",
    "    step_list=[]\n",
    "    fc_list=[]\n",
    "    for items in data[5:]:\n",
    "        nitems = [float(i) for i in items]\n",
    "        step_list.append(nitems[0])\n",
    "        fc_list.append(nitems[1])\n",
    "        data_list.append(tuple(nitems[0:6])+(np.array(nitems[6:]),))\n",
    "        \n",
    "\n",
    "agent.load(F\"data/{file_name}.h5\")\n",
    "print(\"Parameters:\")\n",
    "print(parameters)\n",
    "print(\"\\nModel:\")\n",
    "print(agent.qnet)\n",
    "\n",
    "print(\"\\nMean collected food:\")\n",
    "#Plotting\n",
    "plt.plot(step_list, fc_list, label = \"Mean\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Visualize and Record Gameplay"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Completed: True\n",
      "Episode: 0 Food Collected: [26]\n",
      "Wall time: 2.95 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "env = SingleSnake(num_envs=1, size=10, observation_mode='one_channel', device= DEFAULT_DEVICE)\n",
    "agent.evaluate()\n",
    "PATH = os.getcwd()\n",
    "state = env.reset()\n",
    "for episode in range(1):\n",
    "    fc_sum = 0\n",
    "    recorder = VideoRecorder(env, path=PATH + f'/videos/imperfect snake.mp4')\n",
    "    env.render()\n",
    "    recorder.capture_frame()\n",
    "    #time.sleep(0.2)\n",
    "    counter = 0\n",
    "    while(1):\n",
    "        counter+=1\n",
    "        action = agent.epsilon_greedy_action(env, state , 0.0)\n",
    "        next_state, reward, terminal, _ = env.step(action)\n",
    "        fc_sum+= (reward>0).cpu().numpy()\n",
    "        env.render()\n",
    "        recorder.capture_frame()\n",
    "        #time.sleep(0.2)\n",
    "        state = next_state\n",
    "        if terminal.all() or counter==500:\n",
    "            recorder.close()\n",
    "            break\n",
    "    print(\"Completed:\", terminal.any().cpu().numpy())\n",
    "    print('Episode:', episode, 'Food Collected:', fc_sum)\n",
    "\n",
    "env.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'NoneType' object has no attribute 'window'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-15-1baceacf4cb1>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0menv\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mclose\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m~\\OneDrive - University of Bath\\Reinforcement Learning\\Fast Snake\\wurm\\envs\\simple_gridworld.py\u001b[0m in \u001b[0;36mclose\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    369\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    370\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mclose\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 371\u001b[1;33m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mviewer\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mwindow\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mclose\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    372\u001b[0m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mviewer\u001b[0m\u001b[1;33m=\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    373\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mAttributeError\u001b[0m: 'NoneType' object has no attribute 'window'"
     ]
    }
   ],
   "source": [
    "env.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Computing Average Return"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_env = SimpleGridworld(num_envs=num_envs, size=10, observation_mode='one_channel', device= DEFAULT_DEVICE, auto_reset=False)\n",
    "agent.evaluate()\n",
    "\n",
    "                       \n",
    "t_state = test_env.reset()\n",
    "fc_sum = torch.zeros((num_envs,)).float().to(DEFAULT_DEVICE) #foot collected\n",
    "\n",
    "for steps in range(1000): #max steps\n",
    "    t_action = agent.epsilon_greedy_action(test_env, t_state , 0.0)\n",
    "    t_next_state, t_reward, t_terminal, _ = test_env.step(t_action)\n",
    "    #anything with a positive reward is considered as food.\n",
    "    fc_sum+=(t_reward>0).float()\n",
    "    t_state = t_next_state\n",
    "    if t_terminal.all():\n",
    "        break\n",
    "\n",
    "t_sum = fc_sum.cpu().numpy()\n",
    "t_mean = np.mean(t_sum)\n",
    "print(\"Completed:\", t_terminal.sum().cpu().numpy())\n",
    "print(\"Mean, Median, Max, Min, std:\", \n",
    "      t_mean, \n",
    "      np.median(t_sum),\n",
    "      np.max(t_sum),\n",
    "      np.min(t_sum),\n",
    "      np.std(t_sum))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
