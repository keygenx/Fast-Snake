{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from IPython.display import clear_output, display\n",
    "import torch\n",
    "import random\n",
    "import copy\n",
    "import time\n",
    "import os #to get current working directory\n",
    "import matplotlib.pyplot as plt\n",
    "import pickle #for storing data\n",
    "from wurm.envs import SingleSnake\n",
    "from wurm.envs import SimpleGridworld\n",
    "from gym.wrappers.monitoring.video_recorder import VideoRecorder\n",
    "\n",
    "DEFAULT_DEVICE = 'cuda' #set device"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Visualizing the neural network. Requires Tensorboard"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "from torch.utils.tensorboard import SummaryWriter\n",
    "writer = SummaryWriter()\n",
    "writer.add_graph(qnet, torch.Tensor(env.reset()))\n",
    "writer.close()\n",
    "%load_ext tensorboard\n",
    "%tensorboard --logdir=runs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Replay Buffer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 414,
   "metadata": {},
   "outputs": [],
   "source": [
    "import collections\n",
    "\n",
    "class ReplayBuffer():\n",
    "    def __init__(self, max_buffer_size: int):\n",
    "        #data must be of the form (state,next_state,action,reward,terminal)\n",
    "        self.buffer = collections.deque(maxlen=max_buffer_size)\n",
    "\n",
    "    def add_to_buffer(self, data):\n",
    "        #data must be of the form (state,next_state,action,reward,terminal)\n",
    "        self.buffer.append(data)\n",
    "        \n",
    "    #Sample superbatches and sub sample parallel environments\n",
    "    def sample_subbatch(self,superbatch_length, subbatch_length):\n",
    "        states = []\n",
    "        next_states = []\n",
    "        actions = []\n",
    "        rewards = []\n",
    "        terminals = []\n",
    "        sub_length = self.buffer[0][0].shape[0]\n",
    "        for rand_int in np.random.randint(0, len(self.buffer), superbatch_length):\n",
    "            rand_int_1 = np.random.randint(0, sub_length, subbatch_length)\n",
    "            transition = self.buffer[rand_int]\n",
    "            states.append(transition[0][rand_int_1])\n",
    "            next_states.append(transition[1][rand_int_1])\n",
    "            actions.append(transition[2][rand_int_1])\n",
    "            rewards.append(transition[3][rand_int_1])\n",
    "            terminals.append(transition[4][rand_int_1])\n",
    "        return torch.cat(states), torch.cat(next_states), torch.cat(actions), torch.cat(rewards), torch.cat(terminals)\n",
    "\n",
    "    def sample_superbatch(self,superbatch_length):\n",
    "        states = []\n",
    "        next_states = []\n",
    "        actions = []\n",
    "        rewards = []\n",
    "        terminals = []\n",
    "        for rand_int in np.random.randint(0, len(self.buffer), superbatch_length):\n",
    "            transition = self.buffer[rand_int]\n",
    "            states.append(transition[0])\n",
    "            next_states.append(transition[1])\n",
    "            actions.append(transition[2])\n",
    "            rewards.append(transition[3])\n",
    "            terminals.append(transition[4])\n",
    "        return torch.cat(states), torch.cat(next_states), torch.cat(actions), torch.cat(rewards), torch.cat(terminals)\n",
    "    \n",
    "    #sample parallel environments of subbatch_length from a randomly selected buffer location.\n",
    "    def sample(self, subbatch_length):\n",
    "            rand_int = np.random.randint(0, len(self.buffer))\n",
    "            rand_int_1 = np.random.randint(0, len(self.buffer[0][0]), subbatch_length)\n",
    "            transition = self.buffer[rand_int]\n",
    "            states=transition[0][rand_int_1]\n",
    "            next_states=transition[1][rand_int_1]\n",
    "            actions=transition[2][rand_int_1]\n",
    "            rewards=transition[3][rand_int_1]\n",
    "            terminals=transition[4][rand_int_1]\n",
    "            return (states,next_states,actions,rewards,terminals)\n",
    "\n",
    "        \n",
    "#A buffer with lesser correlation between samples. Implemented with pytorch. \n",
    "#Presently not working properly. Not sure why.\n",
    "class BetterBuffer():\n",
    "    def __init__(self, max_envs: int = 1000):\n",
    "        #data must be of the form (state,next_state,action,reward,terminal)\n",
    "        self.buffer_0 = torch.empty(0).to(DEFAULT_DEVICE)\n",
    "        self.buffer_1 = torch.empty(0).to(DEFAULT_DEVICE)\n",
    "        self.buffer_2 = torch.empty(0).long().to(DEFAULT_DEVICE)\n",
    "        self.buffer_3 = torch.empty(0).to(DEFAULT_DEVICE)\n",
    "        self.buffer_4 = torch.empty(0).bool().to(DEFAULT_DEVICE)\n",
    "        self.max_length = max_envs\n",
    "        self.pointer = 0\n",
    "        self.full = False\n",
    "\n",
    "    def add_to_buffer(self, data):\n",
    "        #data must be of the form (state,next_state,action,reward,terminal)\n",
    "        if self.full == True:\n",
    "            if self.pointer==self.max_length:\n",
    "                self.pointer=0\n",
    "            self.buffer_0[self.pointer*num_envs:(self.pointer+1)*num_envs] = data[0]\n",
    "            self.buffer_1[self.pointer*num_envs:(self.pointer+1)*num_envs] = data[1]\n",
    "            self.buffer_2[self.pointer*num_envs:(self.pointer+1)*num_envs] = data[2]\n",
    "            self.buffer_3[self.pointer*num_envs:(self.pointer+1)*num_envs] = data[3]\n",
    "            self.buffer_4[self.pointer*num_envs:(self.pointer+1)*num_envs] = data[4]\n",
    "            self.pointer+=1\n",
    "        else:\n",
    "            self.buffer_0=torch.cat((self.buffer_0,data[0]))\n",
    "            self.buffer_1=torch.cat((self.buffer_1,data[1]))\n",
    "            self.buffer_2=torch.cat((self.buffer_2,data[2]))\n",
    "            self.buffer_3=torch.cat((self.buffer_3,data[3]))\n",
    "            self.buffer_4=torch.cat((self.buffer_4,data[4]))\n",
    "            self.pointer+=1\n",
    "            if self.pointer==self.max_length:\n",
    "                self.full=True\n",
    "        \n",
    "    def sample(self, batch_size):\n",
    "        if self.full == True:\n",
    "            randint = torch.randint(0, self.max_length*num_envs,(batch_size,))\n",
    "        else:\n",
    "            randint = torch.randint(0,self.pointer*num_envs, (batch_size,))\n",
    "        return self.buffer_0[randint], self.buffer_1[randint], self.buffer_2[randint], self.buffer_3[randint], self.buffer_4[randint]\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## DQN Agent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 425,
   "metadata": {},
   "outputs": [],
   "source": [
    "#################Simple DQN Agent########################################\n",
    "class DQNAgent():\n",
    "    def __init__(self, NN: object, NN_args: tuple = (), \n",
    "                 num_envs: int = 1, buffer_size: int = 800, \n",
    "                 lr: float = 0.0005, discount: float = 0.8, tau: float = 0.01,\n",
    "                 lam = 10):\n",
    "        #self.qnet = torch.load(\"dqn80x80.h5\")\n",
    "        self.qnet = NN(*NN_args)\n",
    "        \n",
    "        self.qnet_target = copy.deepcopy(self.qnet)\n",
    "        for param in self.qnet_target.parameters():\n",
    "            param.requires_grad = False\n",
    "    \n",
    "        self.qnet_optim = torch.optim.Adam( self.qnet.parameters(), lr=lr) #set learning rate\n",
    "        self.discount_factor = torch.Tensor([discount]).to(DEFAULT_DEVICE) # set discount factor\n",
    "        self.MSELoss_function = torch.nn.MSELoss()\n",
    "        self.replay_buffer = ReplayBuffer(buffer_size) #set size of replay buffer.\n",
    "        self.old_buffer = ReplayBuffer(300)\n",
    "        \n",
    "        self.target_update_interval = 500 #set for target update interval for hard target network updates\n",
    "        self.update_count= 0 #internal working variable. Don't change\n",
    "        self.tau = tau # set tau for soft target network updates\n",
    "        self.num_envs = num_envs\n",
    "        self.ewc_counter = 0 #flag keep track of fisher matrix computations.\n",
    "        self.lam = torch.Tensor([lam]).to(DEFAULT_DEVICE)\n",
    "        self.ewc_on = False\n",
    "        \n",
    "    def add_to_buffer(self, data):\n",
    "        self.replay_buffer.add_to_buffer(data)\n",
    "    \n",
    "    #computing diagonal of fisher matrix\n",
    "    def compute_fisher_diagonal(self, data):\n",
    "        print(\"Computing Fisher diagonal...\")\n",
    "        self.params = [p for p in agent.qnet.parameters()]\n",
    "        self.theta_star = [p.data for p in copy.deepcopy(self.params)]\n",
    "        matrix = [p.data*0 for p in copy.deepcopy(self.params)]\n",
    "        \n",
    "        for st in data:\n",
    "            agent.qnet.zero_grad()\n",
    "            output = agent.qnet(st.unsqueeze(0))\n",
    "            label = output.max(dim=1)[1]\n",
    "            lsm = torch.nn.functional.log_softmax(output, dim=1)\n",
    "            loss = torch.nn.functional.nll_loss(lsm, label)\n",
    "            temp = torch.autograd.grad(loss,self.params)\n",
    "    \n",
    "            for n in range(len(matrix)):\n",
    "                matrix[n]+=temp[n]**2\n",
    "\n",
    "        for n in range(len(matrix)):\n",
    "            matrix[n]/=data.shape[0]\n",
    "        self.fisher = matrix\n",
    "        print(\"Computing Fisher diagonal completed.\")\n",
    "\n",
    "    #Computing EWC loss using diagonal of fisher matrix  \n",
    "    #Based on https://arxiv.org/abs/1612.00796\n",
    "    def ewc_loss(self):\n",
    "        loss = 0\n",
    "        for n in range(len(self.fisher)):\n",
    "            loss+=(self.fisher[n]*(self.params[n]-self.theta_star[n])**2).sum()\n",
    "        return loss*self.lam\n",
    "    \n",
    "    def train(self):\n",
    "        self.qnet.train()\n",
    "        torch.set_grad_enabled(True)\n",
    "        \n",
    "    def evaluate(self):\n",
    "        self.qnet.eval()\n",
    "        torch.set_grad_enabled(False)\n",
    "        \n",
    "    #Hard update target network\n",
    "    def target_update(self,network,target_network):\n",
    "        for net_params, target_net_params in zip(network.parameters(), target_network.parameters()):\n",
    "            target_net_params.data.copy_(net_params.data)\n",
    "     \n",
    "    #Soft update target network\n",
    "    def soft_target_update(self,network,target_network):\n",
    "        for net_params, target_net_params in zip(network.parameters(), target_network.parameters()):\n",
    "            target_net_params.data.copy_(net_params.data*self.tau + (1-self.tau)*target_net_params)\n",
    "    \n",
    "    def epsilon_greedy_action(self, state, epsilon):\n",
    "        if np.random.uniform(0, 1) < epsilon:\n",
    "                return env.random_action()  # choose random action\n",
    "        else:                \n",
    "            return torch.argmax(self.qnet(state), dim=1)  # choose greedy action\n",
    "    \n",
    "    #update Q Network by calculating gradient of neural network loss\n",
    "    def update_Q_Network(self, state, next_state, action, reward, terminals):\n",
    "        qsa = torch.gather(self.qnet(state), dim=1, index=action.unsqueeze(-1)).squeeze()\n",
    "        qsa_next_action = self.qnet_target(next_state)\n",
    "        qsa_next_action = torch.max(qsa_next_action, dim=1)[0]\n",
    "        not_terminals = ~terminals\n",
    "        qsa_next_target = reward + not_terminals * self.discount_factor * qsa_next_action\n",
    "        \n",
    "        q_network_loss = self.MSELoss_function(qsa, qsa_next_target.detach())\n",
    "        #EWC loss\n",
    "        if self.ewc_on:\n",
    "            q_network_loss+=self.ewc_loss()\n",
    "\n",
    "        #Gradient descent\n",
    "        self.qnet_optim.zero_grad()\n",
    "        q_network_loss.backward()\n",
    "        self.qnet_optim.step()\n",
    "     \n",
    "    #call this to update Q network (train) and then make hard update of target network\n",
    "    def hard_update(self, update_rate):\n",
    "        for _ in range(update_rate):\n",
    "            states, next_states, actions, rewards, terminals = self.replay_buffer.sample(self.num_envs//3)\n",
    "            self.update_Q_Network(states, next_states, actions, rewards, terminals)\n",
    "            self.update_count+=1\n",
    "            if self.update_count==self.target_update_interval:\n",
    "                self.target_update(self.qnet, self.qnet_target)\n",
    "                self.update_count=0\n",
    "                \n",
    "    #call this to update Q network (train) and then make soft update of target network\n",
    "    def update(self, update_rate, batch_size = 100):\n",
    "        if self.ewc_on:\n",
    "            if self.ewc_counter%(1000*update_rate)==0:\n",
    "                data = self.replay_buffer.sample_superbatch(3)[0]\n",
    "                self.compute_fisher_diagonal(data)\n",
    "            self.ewc_counter+=1\n",
    "           \n",
    "        for _ in range(update_rate):\n",
    "            states, next_states, actions, rewards, terminals = self.replay_buffer.sample(batch_size)\n",
    "            self.update_Q_Network(states, next_states, actions, rewards, terminals)\n",
    "            self.soft_target_update(self.qnet, self.qnet_target)\n",
    "\n",
    "###############Simple DQN Agent######################################################            \n",
    "\n",
    "#################Double DQN Agent smooth##############################################\n",
    "#Based on https://arxiv.org/abs/1509.06461v3\n",
    "class DDQNAgent_smooth(DQNAgent):\n",
    "    def __init__(self, NN: object, NN_args: tuple = (), \n",
    "                 num_envs: int = 1, buffer_size: int = 800,\n",
    "                 lr: float = 0.0005, discount: float = 0.8, tau: float = 0.01):\n",
    "        super().__init__(NN, NN_args, num_envs, buffer_size, lr, discount, tau)\n",
    "    \n",
    "    #update Q Network by calculating gradient of neural network loss\n",
    "    def update_Q_Network(self, state, next_state, action, reward, terminals):\n",
    "        qsa = torch.gather(self.qnet(state), dim=1, index=action.unsqueeze(-1)).squeeze()\n",
    "        q_target_next_state_a = self.qnet_target(next_state)\n",
    "        q_target_next_state_max_a = torch.argmax(q_target_next_state_a, dim=1)\n",
    "        q_next_state_a = torch.gather(self.qnet(next_state), dim=1, index=q_target_next_state_max_a.unsqueeze(-1)).squeeze()\n",
    "        not_terminals = ~terminals\n",
    "        qsa_next_target = reward + not_terminals * self.discount_factor * q_next_state_a\n",
    "        \n",
    "        q_network_loss = self.MSELoss_function(qsa, qsa_next_target.detach())\n",
    "        if self.ewc_on:\n",
    "          q_network_loss+=self.ewc_loss()\n",
    "            \n",
    "        self.qnet_optim.zero_grad()\n",
    "        q_network_loss.backward()\n",
    "        self.qnet_optim.step()\n",
    "        \n",
    "            \n",
    "#################Double DQN Agent smooth##################################\n",
    "\n",
    "#################Double DQN Agent########################################\n",
    "#Based on https://arxiv.org/abs/1509.06461v1\n",
    "class DDQNAgent(DQNAgent):\n",
    "    def __init__(self, NN: object, NN_args: tuple = (), \n",
    "                 num_envs: int = 1, buffer_size: int = 800,\n",
    "                 lr: float = 0.0005, discount: float = 0.8):\n",
    "        #self.qnet = torch.load(\"dqn80x80.h5\")\n",
    "        self.Q_A = NN(*NN_args)\n",
    "        self.Q_B = NN(*NN_args)\n",
    "        self.Q_A_optim = torch.optim.Adam( self.Q_A.parameters(), lr=lr) #set learning rate\n",
    "        self.Q_B_optim = torch.optim.Adam( self.Q_B.parameters(), lr=lr) #set learning rate\n",
    "        self.discount_factor = torch.Tensor([discount]).to(DEFAULT_DEVICE) # set discount factor\n",
    "        self.MSELoss_function = torch.nn.MSELoss()\n",
    "        self.replay_buffer = ReplayBuffer(buffer_size) #set size of replay buffer.\n",
    "        self.num_envs = num_envs\n",
    "        pass\n",
    "    \n",
    "    def train(self):\n",
    "        self.Q_A.train()\n",
    "        self.Q_A.train()\n",
    "        torch.set_grad_enabled(True)\n",
    "        \n",
    "    def evaluate(self):\n",
    "        self.Q_A.eval()\n",
    "        self.Q_B.eval()\n",
    "        torch.set_grad_enabled(False)\n",
    "    \n",
    "    def epsilon_greedy_action(self, state, epsilon):\n",
    "        if np.random.uniform(0, 1) < epsilon:\n",
    "                return env.random_action()  # choose random action\n",
    "        else:                \n",
    "            return torch.argmax(self.Q_A(state), dim=1)  # choose greedy action\n",
    "    \n",
    "    #update Q Network by calculating gradient of neural network loss\n",
    "    def update_Q_A_Network(self, state, next_state, action, reward, terminals):\n",
    "        QA_s_a = torch.gather(self.Q_A(state), dim=1, index=action.unsqueeze(-1)).squeeze()\n",
    "        QA_sn_a = self.Q_A(next_state)\n",
    "        QA_sn_a_max = torch.argmax(QA_sn_a, dim=1)\n",
    "        QB_sn_a = torch.gather(self.Q_B(next_state), dim=1, index=QA_sn_a_max.unsqueeze(-1)).squeeze()\n",
    "        not_terminals = ~terminals\n",
    "        QA_s_a_target = reward + not_terminals * self.discount_factor * QB_sn_a\n",
    "        q_network_loss = self.MSELoss_function(QA_s_a, QA_s_a_target.detach())\n",
    "        self.Q_A_optim.zero_grad()\n",
    "        q_network_loss.backward()\n",
    "        self.Q_A_optim.step()\n",
    "        \n",
    "    def update_Q_B_Network(self, state, next_state, action, reward, terminals):\n",
    "        QB_s_a = torch.gather(self.Q_B(state), dim=1, index=action.unsqueeze(-1)).squeeze()\n",
    "        QB_sn_a = self.Q_B(next_state)\n",
    "        QB_sn_a_max = torch.argmax(QB_sn_a, dim=1)\n",
    "        QA_sn_a = torch.gather(self.Q_A(next_state), dim=1, index=QB_sn_a_max.unsqueeze(-1)).squeeze()\n",
    "        not_terminals = ~terminals\n",
    "        QB_s_a_target = reward + not_terminals * self.discount_factor * QA_sn_a\n",
    "        q_network_loss = self.MSELoss_function(QB_s_a, QB_s_a_target.detach())\n",
    "\n",
    "        self.Q_B_optim.zero_grad()\n",
    "        q_network_loss.backward()\n",
    "        self.Q_B_optim.step()\n",
    "        \n",
    "    #call this to update Q network (train) and then make soft update of target network\n",
    "    def update(self, update_rate, batch_size):\n",
    "        for _ in range(update_rate):\n",
    "            states, next_states, actions, rewards, terminals = self.replay_buffer.sample(batch_size)\n",
    "            if np.random.uniform()<0.5:\n",
    "                self.update_Q_A_Network(states, next_states, actions, rewards, terminals)\n",
    "            else:\n",
    "                self.update_Q_B_Network(states, next_states, actions, rewards, terminals)\n",
    "#################Double DQN Agent##############################################"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Defining Some Neural Networks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 435,
   "metadata": {},
   "outputs": [],
   "source": [
    "# defining a fully connected neural network\n",
    "def FNN_1(shape, hidden_dim, action_dim):\n",
    "    flat_shape = np.product(shape) #length of the flattened state\n",
    "    model = torch.nn.Sequential(\n",
    "        torch.nn.Flatten(),\n",
    "        torch.nn.Linear(flat_shape,hidden_dim),\n",
    "        #torch.nn.Dropout(0.5),\n",
    "        torch.nn.ReLU(),\n",
    "        torch.nn.Linear(hidden_dim,hidden_dim),\n",
    "        #torch.nn.Dropout(0.5),\n",
    "        torch.nn.ReLU(),\n",
    "        torch.nn.Linear(hidden_dim, action_dim),\n",
    "         ).to(DEFAULT_DEVICE)\n",
    "    return model\n",
    "\n",
    "def CNN_1():\n",
    "    model = torch.nn.Sequential(\n",
    "        torch.nn.Conv2d(1, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1)),\n",
    "        torch.nn.ReLU(),\n",
    "        torch.nn.Conv2d(32, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1)),\n",
    "        torch.nn.Dropout(0.1),\n",
    "        torch.nn.ReLU(),\n",
    "        torch.nn.Conv2d(64, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1)),\n",
    "        torch.nn.Dropout(0.2),\n",
    "        torch.nn.ReLU(),\n",
    "        torch.nn.AdaptiveMaxPool2d((1,1)),\n",
    "        torch.nn.Flatten(),\n",
    "        torch.nn.Linear(128, 128),\n",
    "        torch.nn.Dropout(0.5),\n",
    "        torch.nn.ReLU(),\n",
    "        torch.nn.Linear(128, 4),\n",
    "        ).to(DEFAULT_DEVICE)\n",
    "    return model\n",
    "\n",
    "def CNN_2():\n",
    "    model = torch.nn.Sequential(\n",
    "        torch.nn.Conv2d(1, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1)),\n",
    "        torch.nn.ReLU(),\n",
    "        torch.nn.Conv2d(32, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1)),\n",
    "        torch.nn.Dropout(0.1),\n",
    "        torch.nn.ReLU(),\n",
    "        torch.nn.Conv2d(64, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1)),\n",
    "        torch.nn.Dropout(0.2),\n",
    "        torch.nn.ReLU(),\n",
    "        torch.nn.AdaptiveMaxPool2d((1,1)),\n",
    "        torch.nn.Flatten(),\n",
    "        torch.nn.Linear(128, 128),\n",
    "        torch.nn.Dropout(0.5),\n",
    "        torch.nn.ReLU(),\n",
    "        torch.nn.Linear(128, 128),\n",
    "        torch.nn.Dropout(0.5),\n",
    "        torch.nn.ReLU(),\n",
    "        torch.nn.Linear(128, 4),\n",
    "        ).to(DEFAULT_DEVICE)\n",
    "    return model\n",
    "\n",
    "def CNN_3():\n",
    "    model = torch.nn.Sequential(\n",
    "        torch.nn.Conv2d(1, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1)),\n",
    "        torch.nn.ReLU(),\n",
    "        torch.nn.Conv2d(32, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1)),\n",
    "        torch.nn.AdaptiveMaxPool2d((1,1)),\n",
    "        torch.nn.Flatten(),\n",
    "        torch.nn.Linear(64, 128),\n",
    "        #torch.nn.Dropout(0.2),\n",
    "        torch.nn.ReLU(),\n",
    "        torch.nn.Linear(128, 4),\n",
    "        ).to(DEFAULT_DEVICE)\n",
    "    return model\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Initializing Environment and Agent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 434,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sequential(\n",
      "  (0): Conv2d(1, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "  (1): ReLU()\n",
      "  (2): Conv2d(32, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "  (3): AdaptiveMaxPool2d(output_size=(1, 1))\n",
      "  (4): Flatten()\n",
      "  (5): Linear(in_features=64, out_features=128, bias=True)\n",
      "  (6): ReLU()\n",
      "  (7): Linear(in_features=128, out_features=4, bias=True)\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "environment = 'SingleSnake'\n",
    "num_envs = 1300 #Number of parallel environments to simulate. Use small value for cpu (eg. 1)\n",
    "test_num_envs = 100\n",
    "\n",
    "if environment == 'SimpleGridworld':\n",
    "    env = SimpleGridworld(num_envs=num_envs, size=10, observation_mode='one_channel', device= DEFAULT_DEVICE)\n",
    "    test_env = SimpleGridworld(num_envs=test_num_envs, size=10, observation_mode='one_channel', device= DEFAULT_DEVICE, auto_reset=False)\n",
    "\n",
    "    state = env.reset()\n",
    "    state_dim = state.shape[1:]\n",
    "    action_dim = 4\n",
    "\n",
    "    #Effective buffer_size = buffer_size*num_envs\n",
    "    agent=DDQNAgent_smooth(NN = CNN_1, #NN_args = (state_dim, 512, action_dim),\n",
    "                           num_envs = num_envs, buffer_size = 600, lr = 0.0005,\n",
    "                           discount = 0.8, tau =0.01)\n",
    "\n",
    "\n",
    "elif environment == 'SingleSnake':\n",
    "    env = SingleSnake(num_envs=num_envs, size=10, observation_mode='one_channel', device= DEFAULT_DEVICE)\n",
    "    test_env = SingleSnake(num_envs=test_num_envs, size=10, observation_mode='one_channel', device= DEFAULT_DEVICE, auto_reset=False)\n",
    "\n",
    "    state = env.reset()\n",
    "    state_dim = state.shape[1:]\n",
    "    action_dim = 4\n",
    "\n",
    "    #Effective buffer_size = buffer_size*num_envs\n",
    "    agent=DDQNAgent_smooth(NN = CNN_3, num_envs = num_envs, buffer_size = 600, lr = 0.0005, discount = 0.8, tau =0.01)\n",
    "\n",
    "else:\n",
    "    raise Exception(\"Invalid option\")\n",
    "    \n",
    "agent.train()\n",
    "print(agent.qnet)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 433,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wall time: 3.07 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "#theta = torch.nn.utils.parameters_to_vector(agent.qnet.parameters())\n",
    "params = [p for p in agent.qnet.parameters()]\n",
    "theta_star = [p.data for p in copy.deepcopy(params)]\n",
    "matrix = [p.data*0 for p in copy.deepcopy(params)]\n",
    "\n",
    "data = state\n",
    "for st in data:\n",
    "    agent.qnet.zero_grad()\n",
    "    output = agent.qnet(st.unsqueeze(0))\n",
    "    label = output.max(dim=1)[1]\n",
    "    lsm = torch.nn.functional.log_softmax(output, dim=1)\n",
    "    loss = torch.nn.functional.nll_loss(lsm, label)\n",
    "    temp = torch.autograd.grad(loss,params)\n",
    "    \n",
    "    for n in range(len(matrix)):\n",
    "        matrix[n]+=temp[n]**2\n",
    "  \n",
    "for n in range(len(matrix)):\n",
    "    matrix[n]/=len(data)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 436,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-436-82c806a675c7>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     26\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mnumber_of_episodes\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     27\u001b[0m     \u001b[0maction\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0magent\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mepsilon_greedy_action\u001b[0m\u001b[1;33m(\u001b[0m \u001b[0mstate\u001b[0m \u001b[1;33m,\u001b[0m \u001b[0mepsilon\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;31m#set epsilon\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 28\u001b[1;33m     \u001b[0mnext_state\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mreward\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mterminal\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0m_\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0menv\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mstep\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0maction\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     29\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     30\u001b[0m     \u001b[0magent\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0madd_to_buffer\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mstate\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mnext_state\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0maction\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mreward\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mterminal\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\OneDrive - University of Bath\\Reinforcement Learning\\Fast Snake\\wurm\\envs\\single_snake.py\u001b[0m in \u001b[0;36mstep\u001b[1;34m(self, actions)\u001b[0m\n\u001b[0;32m    226\u001b[0m             \u001b[1;32mraise\u001b[0m \u001b[0mRuntimeError\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'Must have the same number of actions as environments.'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    227\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 228\u001b[1;33m         \u001b[0mreward\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mzeros\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mnum_envs\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfloat\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mto\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdevice\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mrequires_grad_\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;32mFalse\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    229\u001b[0m         \u001b[0mdone\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mzeros\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mnum_envs\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mbool\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mto\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdevice\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mrequires_grad_\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;32mFalse\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    230\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "#%%time\n",
    "render=False\n",
    "save_model = False\n",
    "number_of_episodes = 100000\n",
    "epsilon = 1.0\n",
    "####Code to compute total reward####\n",
    "\n",
    "total_reward = torch.zeros(num_envs).to(DEFAULT_DEVICE)\n",
    "episode_list=[]\n",
    "fc_list=[] #food collected\n",
    "best_fc = 0\n",
    "####Code to compute total reward####\n",
    "\n",
    "state=env.reset()\n",
    "agent.train()\n",
    "\n",
    "#Filling up the buffer\n",
    "for i in range(30):\n",
    "    action = agent.epsilon_greedy_action( state , 1.0) #set epsilon\n",
    "    next_state, reward, terminal, _ = env.step(action)\n",
    "    agent.add_to_buffer((state,next_state,action,reward,terminal))\n",
    "    state = next_state\n",
    "\n",
    "\n",
    "#Learning\n",
    "for i in range(0,number_of_episodes):\n",
    "    \n",
    "    action = agent.epsilon_greedy_action( state , epsilon) #set epsilon\n",
    "    next_state, reward, terminal, _ = env.step(action)\n",
    "    agent.add_to_buffer((state,next_state,action,reward,terminal))\n",
    "    agent.update(update_rate=10, batch_size=400)\n",
    "    state = next_state\n",
    "    \n",
    "    if i%1000==0:\n",
    "        self.ewc_on=True #Turning on EWC\n",
    "        self.lam=100 #Setting scalar parameter in EWC loss function\n",
    "    \n",
    "    if i==1000:\n",
    "        epsilon = 0.1\n",
    "    elif i==3000:\n",
    "        epsilon = 0.01\n",
    "    elif i==5000:\n",
    "        epsilon = 0.001\n",
    "    elif i==10000:\n",
    "        epsilon = 0.0001\n",
    "    elif i==15000:\n",
    "        epsilon = 0.00001\n",
    "    elif i==15000:\n",
    "        epsilon = 0.000001\n",
    "    \n",
    "    if render:\n",
    "        env.render()\n",
    "\n",
    "    #New code for recording data. Slower but more accurate.\n",
    "    if (i%100==0):\n",
    "        agent.evaluate()                        \n",
    "        t_state = test_env.reset()\n",
    "        fc_sum = torch.zeros((test_num_envs,)).float().to(DEFAULT_DEVICE) #foot collected\n",
    "        #hit_terminal = torch.zeros((test_num_envs,)).bool().to(DEFAULT_DEVICE)\n",
    "\n",
    "        for steps in range(1000): #max steps\n",
    "            t_action = agent.epsilon_greedy_action( t_state , 0.0)\n",
    "            t_next_state, t_reward, t_terminal, _ = test_env.step(t_action)\n",
    "            #anything with a positive reward is considered as food.\n",
    "            fc_sum+=(t_reward>0).float()\n",
    "            #hit_terminal |= t_terminal\n",
    "            t_state = t_next_state\n",
    "            if t_terminal.all():\n",
    "                break\n",
    "\n",
    "        t_sum = fc_sum.cpu().numpy()\n",
    "        t_mean = np.mean(t_sum)\n",
    "        print('episode:', i)\n",
    "        print(\"Completed:\", t_terminal.sum().cpu().numpy(), \"/\", test_num_envs)\n",
    "        print(\"Mean, Median, Max, Min, std:\", \n",
    "              t_mean, \n",
    "              np.median(t_sum),\n",
    "              np.max(t_sum),\n",
    "              np.min(t_sum),\n",
    "              np.std(t_sum))\n",
    "        fc_list.append(t_mean)\n",
    "        episode_list.append(i)\n",
    "        plt.plot(episode_list, fc_list)\n",
    "        plt.show()\n",
    "        agent.train()\n",
    "        clear_output(wait=True)\n",
    "        if t_mean>best_fc:\n",
    "            best_fc = t_mean\n",
    "            torch.save(agent.qnet,\"models/best_model.h5\")\n",
    "    \n",
    "if render:    \n",
    "    env.close()\n",
    "    \n",
    "if save_model:\n",
    "    model = torch.load(\"best_model.h5\")\n",
    "    with open('models/best_model.pickle', 'wb') as f:\n",
    "        pickle.dump((model, episode_list,reward_list), f)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Storing Data of best model and associated runtime data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 437,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "#Visualizing reward\n",
    "plt.plot(episode_list, fc_list)\n",
    "plt.show()\n",
    "\n",
    "#agent.qnet = torch.load(\"models/bestest_model(1).h5\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 432,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[[ 2.1101e-03,  9.7468e-04, -5.7731e-04],\n",
       "          [ 2.3563e-03,  3.9411e-03,  3.4400e-04],\n",
       "          [ 4.9174e-03,  2.2736e-03,  3.2663e-03]]],\n",
       "\n",
       "\n",
       "        [[[-1.0439e-03, -2.0893e-03, -2.1428e-03],\n",
       "          [-3.2560e-03, -2.2187e-03, -2.7031e-03],\n",
       "          [ 1.5315e-04,  5.7159e-04, -3.5639e-05]]],\n",
       "\n",
       "\n",
       "        [[[ 3.5938e-04,  7.2921e-04, -1.1888e-03],\n",
       "          [-8.2049e-04,  1.7179e-03, -1.2332e-03],\n",
       "          [ 3.1159e-03,  1.7708e-03,  2.9970e-04]]],\n",
       "\n",
       "\n",
       "        [[[ 6.4085e-04,  1.4735e-03, -2.3989e-04],\n",
       "          [-1.0531e-04, -5.3806e-03, -2.3074e-03],\n",
       "          [-4.6372e-03, -2.0209e-03, -3.9466e-03]]],\n",
       "\n",
       "\n",
       "        [[[-3.2835e-03, -5.4476e-03, -5.1719e-03],\n",
       "          [-1.2228e-03, -2.7404e-03, -2.0257e-03],\n",
       "          [-1.4654e-03, -3.4730e-03, -2.5701e-03]]],\n",
       "\n",
       "\n",
       "        [[[-1.1047e-03, -2.0111e-03, -2.3322e-03],\n",
       "          [-2.7463e-04, -2.8320e-03, -2.6048e-03],\n",
       "          [ 7.8570e-04, -2.8060e-04, -1.4255e-04]]],\n",
       "\n",
       "\n",
       "        [[[ 2.0956e-03, -2.5859e-03, -3.2625e-03],\n",
       "          [-4.3287e-03, -3.6205e-03, -5.7902e-03],\n",
       "          [-1.4159e-04, -2.9104e-04, -5.1586e-04]]],\n",
       "\n",
       "\n",
       "        [[[ 6.8914e-04,  4.4004e-03,  1.8619e-03],\n",
       "          [ 1.2974e-03,  4.1647e-03, -4.1131e-05],\n",
       "          [-1.7238e-03, -1.1500e-03, -2.1450e-03]]],\n",
       "\n",
       "\n",
       "        [[[-1.7352e-03, -1.8843e-03,  3.7444e-04],\n",
       "          [-5.0499e-04,  3.1530e-04,  1.0796e-03],\n",
       "          [ 3.3573e-05, -3.9695e-05,  2.2533e-04]]],\n",
       "\n",
       "\n",
       "        [[[-9.2111e-04, -2.5437e-03, -4.4780e-03],\n",
       "          [-3.0015e-03, -1.8063e-03, -3.7093e-03],\n",
       "          [-6.1254e-04, -1.7832e-03, -3.3530e-04]]],\n",
       "\n",
       "\n",
       "        [[[-6.2746e-04,  8.9004e-04,  1.6232e-03],\n",
       "          [ 8.8462e-04,  4.5380e-03,  3.2779e-03],\n",
       "          [ 3.5450e-04,  2.3396e-03,  1.2879e-03]]],\n",
       "\n",
       "\n",
       "        [[[-7.8490e-04,  4.8973e-05, -4.5243e-04],\n",
       "          [-9.3476e-04, -1.8517e-04, -3.0804e-04],\n",
       "          [ 3.5539e-04,  2.5055e-04, -2.0077e-03]]],\n",
       "\n",
       "\n",
       "        [[[-4.3542e-04,  4.4008e-04,  8.0575e-04],\n",
       "          [-3.3949e-04,  1.0629e-03, -6.7336e-05],\n",
       "          [-5.0956e-04, -3.9169e-04, -1.0304e-04]]],\n",
       "\n",
       "\n",
       "        [[[ 2.7070e-05, -8.7311e-04, -6.7078e-04],\n",
       "          [-2.1282e-03,  1.5303e-03, -5.2666e-04],\n",
       "          [ 2.2830e-04,  5.4505e-04,  1.1356e-03]]],\n",
       "\n",
       "\n",
       "        [[[-2.6158e-03, -4.2672e-03, -1.1925e-03],\n",
       "          [-9.5767e-04, -3.0233e-03, -2.0865e-03],\n",
       "          [-2.7465e-03, -1.4431e-03, -1.7710e-03]]],\n",
       "\n",
       "\n",
       "        [[[-3.0877e-04,  1.4982e-03, -5.2949e-04],\n",
       "          [ 3.0743e-04, -1.9623e-05,  1.3638e-04],\n",
       "          [-1.1346e-03, -7.4818e-04, -5.6988e-04]]],\n",
       "\n",
       "\n",
       "        [[[-4.2402e-04, -1.4853e-03, -9.1085e-04],\n",
       "          [-2.8832e-03, -9.1608e-04, -2.1503e-03],\n",
       "          [-9.3966e-05, -5.5544e-04, -6.1408e-04]]],\n",
       "\n",
       "\n",
       "        [[[ 1.1616e-03,  3.2936e-03,  2.1855e-03],\n",
       "          [ 8.9267e-04,  2.4347e-03,  3.4942e-03],\n",
       "          [ 1.8334e-03,  3.2444e-03,  3.5646e-03]]],\n",
       "\n",
       "\n",
       "        [[[ 6.7608e-04, -3.0709e-05, -2.3092e-03],\n",
       "          [-8.0517e-04, -1.4624e-03, -2.2437e-03],\n",
       "          [ 1.3880e-03, -1.3902e-03, -5.8457e-05]]],\n",
       "\n",
       "\n",
       "        [[[-1.8345e-03, -3.2487e-03, -3.4307e-03],\n",
       "          [-2.7754e-03, -3.4433e-03, -1.9287e-03],\n",
       "          [-2.6971e-04, -2.0221e-03, -1.3007e-03]]],\n",
       "\n",
       "\n",
       "        [[[-2.5946e-03, -3.7243e-03, -1.6037e-03],\n",
       "          [ 5.3026e-04,  7.1794e-04,  1.2774e-05],\n",
       "          [ 3.7090e-05,  5.8213e-04, -8.0714e-05]]],\n",
       "\n",
       "\n",
       "        [[[ 3.4429e-04, -1.2506e-03, -6.6266e-05],\n",
       "          [-1.1544e-03, -1.2737e-03, -8.8568e-04],\n",
       "          [-1.3644e-03, -2.0263e-03, -1.1675e-03]]],\n",
       "\n",
       "\n",
       "        [[[-6.6286e-04,  1.5354e-03,  4.7966e-06],\n",
       "          [ 5.0755e-03,  1.1384e-03,  3.1282e-03],\n",
       "          [ 6.5110e-04,  1.6064e-03, -1.2347e-04]]],\n",
       "\n",
       "\n",
       "        [[[ 5.0019e-05, -1.6954e-03, -9.3229e-04],\n",
       "          [ 7.7045e-04,  9.2337e-04,  1.7508e-04],\n",
       "          [ 1.0362e-03,  9.9249e-04, -2.3539e-04]]],\n",
       "\n",
       "\n",
       "        [[[ 2.3122e-04,  7.7054e-04,  1.9993e-04],\n",
       "          [ 1.7759e-03,  1.9078e-03,  1.3525e-03],\n",
       "          [ 6.9293e-05,  7.2683e-04, -9.9607e-04]]],\n",
       "\n",
       "\n",
       "        [[[-1.0389e-03, -7.9671e-04, -9.6443e-04],\n",
       "          [-2.5080e-04, -7.0952e-04,  7.6607e-04],\n",
       "          [-2.0801e-04,  3.1500e-03,  4.4299e-04]]],\n",
       "\n",
       "\n",
       "        [[[ 7.8418e-06, -4.0204e-03, -1.4935e-03],\n",
       "          [-2.4490e-04, -3.1209e-03, -9.7580e-04],\n",
       "          [-6.3829e-04, -7.0942e-04, -1.4053e-05]]],\n",
       "\n",
       "\n",
       "        [[[ 3.7394e-04,  9.3858e-04,  2.0940e-03],\n",
       "          [-1.5237e-03, -3.8177e-04, -2.1457e-03],\n",
       "          [-1.2772e-03, -9.9511e-04, -7.7621e-04]]],\n",
       "\n",
       "\n",
       "        [[[-3.4983e-03, -2.1507e-03, -4.4380e-04],\n",
       "          [-1.2097e-03, -8.3362e-04, -1.2980e-03],\n",
       "          [-4.6060e-04, -1.1788e-03, -4.3458e-04]]],\n",
       "\n",
       "\n",
       "        [[[-1.0502e-03,  7.1878e-04,  2.3960e-04],\n",
       "          [-4.0050e-04, -2.1278e-03, -4.0580e-04],\n",
       "          [ 6.6670e-05,  1.7961e-04, -3.8196e-04]]],\n",
       "\n",
       "\n",
       "        [[[ 1.6158e-04, -4.9167e-04, -3.6330e-04],\n",
       "          [-2.4204e-04, -5.6260e-04, -2.1358e-04],\n",
       "          [-1.8788e-03, -1.3479e-03, -1.1125e-03]]],\n",
       "\n",
       "\n",
       "        [[[-1.0000e-04,  1.0053e-04, -7.3741e-05],\n",
       "          [-1.1953e-04, -9.3181e-05, -3.2780e-04],\n",
       "          [-4.1185e-04,  1.0569e-03, -1.1012e-03]]]], device='cuda:0')"
      ]
     },
     "execution_count": 432,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "list(agent.qnet.parameters())[0].grad"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#Visualizing reward\n",
    "plt.plot(episode_list, fc_list)\n",
    "plt.show()\n",
    "\n",
    "#Store data about the best model as a pickle file\n",
    "import pickle\n",
    "model = torch.load(\"models/best_model.h5\")\n",
    "with open('models/cnn_256_avg_822.pickle', 'xb') as f:\n",
    "    pickle.dump((model, episode_list,reward_list), f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAX4AAAD4CAYAAADrRI2NAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADh0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uMy4xLjMsIGh0dHA6Ly9tYXRwbG90bGliLm9yZy+AADFEAAAgAElEQVR4nO2deXhkVZn/v6f2PUll7yTd6Y3e6A26m272VRZR1BGFcRB1FEfBAccZB8eR8ecyKqg4riMz7iMICAiC7DSbQEPT9L6n1yydPZXUvtzz++Pec+veyq1KJaksVfV+nidPKrduVZ1blfre937f97yHcc5BEARBlA+mmR4AQRAEMb2Q8BMEQZQZJPwEQRBlBgk/QRBEmUHCTxAEUWZYpvPFampqeGtr63S+JEEQRNHz9ttv93HOawv1fNMq/K2trdi6det0viRBEETRwxg7XsjnI6uHIAiizCDhJwiCKDNI+AmCIMoMEn6CIIgyY0zhZ4y1MMY2M8b2Mcb2MMZuVbZ/lTHWwRjbrvxcNfXDJQiCICZLPlU9SQBf4JxvY4x5AbzNGHtWue9uzvl3p254BEEQRKEZU/g5510AupTbI4yxfQCapnpgBEEQxNQwLo+fMdYKYC2ALcqmWxhjOxljv2SMVWV5zE2Msa2Msa29vb2TGixBEIVhKBzHn3d0zvQwiBkib+FnjHkAPATgNs75MICfAVgIYA3kK4LvGT2Oc34P53wd53xdbW3BJp4RBDEJHnmnA5+77x30BWMzPRRiBshL+BljVsii/3vO+cMAwDnv5pynOOcSgP8BsGHqhkkQRCEZjiSV34kZHgkxE+RT1cMA/ALAPs759zXbGzW7vR/A7sIPjyCIqSAYSyi/kzM8EmImyCfiPwfADQAuzijdvJMxtosxthPARQA+P5UDJYhSJCVxfP/Zg+gejk7r6wrBD0ZJ+MuRfKp6XgXADO76S+GHQxBpgrEkntvbjfetLd0istfa+vDD5w+hrTeIn/ztGVP+ers7AthydAAjiuCPUMRfltDMXWLW8tj2Ttx2/3a0D4ZneiiGcM7xi1ePomcS0XrnUAQAYDdPz1fxwa0n8c0n9qrCP1URP+cc//XcIRzuGZmS5ycmBwk/MWvpGZEFdbb60D0jMXz98b14YlfXhJ/jVECuqqn12Qs1rJwMR5OQOHAqML739uRAGCcH8j8Bh+Mp3P3cQTy6nUpGZyMk/MSspT8YBwCEYqkZHokxI1E5QRpJ5B7f/lPD+P0W43bqJ5WrGWbophaegFLFI143X+E/787NOO/OzXm/jnhP+pTPsND0BWPqyYsYPyT8xKylPyRHw+F4YSL+YCyJf/3jTgTChSlhDConpGhCyrnf/W+dxFf+tBuSxEfdd6wvBACIFOgYx0IIfzguj31knFYP56OPwYioKvxTM0/g0u+/hI3fen5Knns8xJIpxJKzMzDJBQk/MWvpGylsxP/OiUHcv/Uk3jjaX5DnE/54dIyIP6jYK0aJ1GP9ivCP8RyFIpBRty/KOvPl4W0duO/NE2PuJ96T/mAMP3r+EF4+WNhZ+0PKyXswNDVXFJkMhuKGJ71b79uOf35w57SMoZCQ8BOzhkA4gQe2nsRTu08BAPoKHPELsZhsFCpJHPe9eQIDYVl0xhL+kDL+zCuN4WhCtUJEBK7lPx7djf94tLDTY0YJ/zgj/i89sgvf+su+MSN/cRXUMxLDD184hIe2tQMAHnjrJL74xx3Yf2p4XK+bja3HB0dtGwrLIr27I4BEKvfVWD50DEVw1n8+b5jLOT4QxqHu4ktgk/ATs4avPb4XX/zjTvzD/70NSeJpj99AFCfCkCJ64koiFycHwnjnxGhRAYC3TwziSw/vwhM75cRlZIzxCUtoKBLH5v09WPeN59AXjKkVPdmeY8vRAbx5LD2GeFLCI++0439fOTLm+LOROVN3MJzAX3Z15W3hxJMShqNJ9I8RaYsrmPbBCBIprvrx97xyBA9sbcdHf/EmkpMQZbfNDADYemxAt/21w31Y87Vncf5dm3H1j17FhXe9OC5hfmp3Fy7+7os6++aVg72IpyS8sK9n1P7BWGLK8hhTCQk/MWvY0T6k3u4YiqT96AJV9QSUCF3kDnJx93MH8dnfbzO8r2NQFuwTA/LvaDK3gIWU8Q+GE/j+swfRF4xh67EBXZRvFPEPhRMY0Iz1F68exefv34FvPLFvQhZHNJFCLGOsLx3sxWd/vw072wNZH2ck0Ed6QzlfK/NE1j0cBecc3YEo6n129IzE8FqbbLm9drgP7/nRq2NeOQHA4Z4RtA+G1RPLWxnC36bkTE4ORPDp8xdgJJrAd585MObzCv7h/7bhSF8IvSPp912M8/Uj/aNOkKFYCgOhmGH+BgB2tQew6qtPz7qyVhJ+YlrY1R7I+uUAZDunrTeItXMrAQDbT6ZPAgWL+Mdh9fSOxHBqOIq4gah3BmTBF/MLxor4hfA/vecUdnXIArujPYCo8ji7xYRwIoW7nt6PHcpxc84xEI5jQOMta8edadnkQ66+PF0GFTLfffoAXm/r173/NmW+wZHeYM7XyhTxU8NRDIUTGIklcePZrfA5LHjknQ4AwJvHBrCrIzBmuSjnHJd+/2Wc+53NEP9K+7pGdP9XQ8oJcf/Xr8CXrlqGj53diqf3dONQ9wi+89R+vHl0wOip1ecXiF5GnHO81tYPh9WErkAUx/v1YwzG5PzNYDiOZEpSK70Ej+/sxHA0OevKWkn4iSnnYPcI3vPjV/Gdp/Zn3Wdf1wg4B648vQEA8M6JtPDnG/Ef7gnm9I7HY/UEIglwDsNWCsK2EBUxWlsgEh9d5SH2e3ZvNwBgUZ0HO04OIars53fbMBSO4yeb21QvPJJIIZ6UkEhxNSmsTQAPR/MX/mgihWgiNepkIewSAOgdiWI4msBF330Rbxzpx872Ifx482H884M71BzLe1fPwQ+uWwO7xYQjfSHs7gjgy4/sMvTRM5PV0YSknvQW13lx2fIGbD7Qo7y2fEJr11hfRhzIsGzWzatCJJFC+2D6cQPhODx2CxxW+dhuPLsVjAG/ef0YfvZiG370wqGsz39Cc+IR79XW44PoC8bw0U2tAIA3jvRjOJpAIiUhnpTUwKAvGMetf9iOK37wiu5E9OIBOan9pJK3mi2Q8BMFJSXxUUnMASUK+/nLo73pvmAMgXACezplUbh8RQMYA945mfa2jSL+lMTxufveUcU0kZLwsV+9iVvv2551bGrEn4fVM6jYQkaRcOeQfps2ur3hF1vwtT/v1d0vkru9IzHUeGw4a74fu9oDqr3jd9vU1xER5YDGyhlQPGTtlYVRxG90dQIAX/zjTtxy77ZRJ4uGCod6u3ckhkPdIzjaF8LTe07hd6/L8w6aq5zqFculy+tx1cpGzK9x40hvEP/9Uht+v+UEHlZOVlpiBiWuwpaZ63dhWaNXsbLi6FGEv2Mwt/Bv3q+vDFo/3w9ADiwEQ+EEKl1W9e9qjx2L6zx4eJt8dfFaW7/uvdXyxpF0tVcgkkAyJeGOR/egwefA5y5ehFqvHa8c6sMl33sJdz19QH1fAODXrx3FE7u60DEUwd4uOfjYfnIIB7pHsKDWjcM9wVll95DwEwXlD2+dwLl3vpBVpLoC+i/3J379Fr78p13Y0zGMKpcVc/0uNPgcqtVjNjHDqp4ndnXhzzs68aft8hf64W3taB+M4FDPyKj9Tw6E8cBbJxGIyF/4vpGxhX8olDAcr9E2bXR7uDeos6kA6ASiqdKJ1c2VGIklceCULAR+t00V7eNKeeeQ5uQpEqnheBJMmeeVKfzH+0M47d+fxGMGi6sc6gniSG9IfYzPIbfoaqxwqvv0jMRwUslZvHKoT32eeEpSk9MeuxxFy8IfgtchC+xPX2wblQfQvicOqywzW46mhX9hnQcA0NYbVCP+zjEi/uf3dev+Xt8qr/10UCOog+E4/G6bbr+1LVXqSTYlcTyzJx19f+nhnfjYr94EIF8xCoYjCbx5dAD7uoZx+5VL4XVYsXFBNZ7c3YXekRgeertd9xn84a2TaFROpC8f6sWTu7rwvp/8FXaLCf/5/pVY3VwxIXtuqiDhJwrKkd4QRqJJ3WW59h/+ub3pL28olsTujgCO94dxYiCMBbUeMMbQ4neBc1n05YhTH/FzzvGj5+VL9v1KdHXvlhOwWUyQOLCvK233bD85hPPu3IwvPrRTtY+Go8mck24SKUm1V4wi/sxtonQxmZIwFE7gSG9IvdyPJVNIpNKX/nMqnWislAVCWBRVrrRQtQ9GkExJ+og/lC75bPDJj80UkXuUq6mXDoyul+8PxjAYjquPmVftBgA4dVZPTLU6DvcEEUtKaK12oT8YV602l82iPr59MKLmHI73h3E4w/PXXgWtaZHzNm8dG0Ct1w6nzYyFNbLwH9EIf8dQBJF4Ct975sCok/efd3Ri6/FBLFJOGADUIOFQd/q1B0NxVLr0wn/GPPn1lzf6UOOxY+vxQexsH8JvXz+G+948iRcP9KJzKIJTwzFUKyeNQCSBI0qi+KwF8pXFpgXVam6hPxTX2TecA+ctrsGyRh9ePtiLh7Z1oKnSief+6QJsXFCNR285F2fO84/6bGYKEv4y4t4tJ9Tk4VQhRGpvZ1p8RVLRbjHpvPs9ncOQuNyTp3skqoqa8Iyv39CCWo99lAi09YZwqCeIpkonjvaFMBxNYF/XCN69Ul4iYpemQuU3rx1TbyclDrOJ6cZphDba7sqIQqOJ1KjHiqubwXC6hcMpJTeQedJqqnSqAioieW2EmpQ4ugJR1WoCZOEWry3sGZF8BGSxe/Bt2W7JrDqRJI6BkCz6g8pVzNxqFwDoKnzkiD/tcbdWu3Dx0nr0B2NqWwePXVwpOBBPSTjUPaKOXRsti/cAAK5e1YgbNrYqY5PFGgCaqpywWUxo6w2hN5i2ejYf6MGPXjg8ytb5xhN7sbqlEl+6cqm6rdJlw+J6j87qGQwn4NdYPQCwdq58ZbBmbiWaqpzoHo7itvu3445H96h5jmf2nEL3cBQLaz0wMVn4TwyEYbOYUO+V3/NNC6sBAJcuq4fXYcGflOS04PSmCly4pBZvHRvEy4d6cemyOrQoxzvbIOEvEySJ46uP7cGvNUI4FYgoUBt1ByIJMCZHRFobZKdSvtkXjONUIIo6pVHZe1fPAQDcdulpcNktqsd/vD8Ezrnqxd6waR4kDjy+owvxlISLl9ahxmPHrg75tWPJFJ7b241r1sxRLZJ5iugZJXi/+cRe/PylNgxpRLczI7oXiV2bppumuHrQlom2KRFw5gSppionXIrYiFLNTGvieH9YV67Zr4n4/S4bbGaTLuJ/40g/4kkJFhNDh3Ki+t3rx/DWsQHZq5Y4JJ6+wphf7QZjwOlzfACAJfVeNeKfX+OG1czwwTObUeO1IRRPqa/vVoRfnHyO9YexodUPxoyF32Yx4cd/ewbevSq9ZtOH17cAkK/m5le7sf3EkGpzdQ5F1Cu4A5okfTCWRPdwDFesaEBTVdqeqnBasbDWo6u0MYr4F9V6cN36Flx7ZjMafHacCkRxKhDFXL8L935qIxbVefD0nm50D0fRUOGAz2nFcDSBY30hzPW7YFKChdZqF265aBFuvWQx5lW7cKRPf8wr5vjwyXPnw2O3IJ6UcMmyesxWSPjLhN5gDPGUpHrIU4WIhjOF3+ewYu3cKhzpC6nJX1E7npK4zsb42NmtOPCNK1DjscNtMyMcS2Jf1zAuuOtFvHiwF28c6UeDz4ErVsgVQA++fRIAsLKpAiubfGqi+JWDfRiJJfG+tU1oVgRjYa1HeT9GWzhP7TmFP+/sVCN3m9mEZ/d24+9//ZYaSQubZ3F92nIQEf+AZiKPqHMX0bLNIn/V5lQ64VYi/oFgHCYmC5iWB98+iUOKkDqsJvU9jcRTcNrM8DktOuF/89gAHFYTLl/RgM5ABPGkhK89vhc/fP6Q7mR0vD8El82Mj26ah5/+7Rn4/GWn4ZHPno1Ll9ehLygL/5qWSjzz+QvwDxcsRI1bPhELC0hEx+JzAuQTWUuVSx2vIJaQ4LSmraS/P3c+/uXyJfjQuhZ124JaN95UEr7zql04NRxVK3/2n0pH8eJk21jhUF/bY7fAajahxmNDMJZENJFSLbqqDOE3mRi+/TersHZuFep9DhwfCCMcT+HvNs7F6pZKnL+4FttODOKUMsegwmlVI/55moidMYZ/vnwJVjZXoNZjVy08m9kExoClDT5Ue+z4+vtOx5qWStUimo2Q8JcJ7eqko6npbb/5QA++/8wBdbbtvq5h1ecORORKC+H1blci/d2dAVUQAaBe+VIzxmC3yKLhslkQjqfUq4PXDvdhy9EBnLXAj7l+F9w2M945MQS3zYy5fhda/C5VnF893Aen1YxzFtZggeIpr5tXBZvFhJcO9OLeLSdw+d0v46nd8lT8oVACbT0hVWiFJfL8/h7VjhD3ab3maFLCUDiO7pH0yUTUuYuKnqZKp/rbpSRJ+0JxOKxm1Wu3KJHlo9s78fstJ1DhtKLGY0dfMIZYMoVwPAWXzSxHpFrhPzqAtS1VsngGoth/ahiJFMdbxwZ0+Yi23iCqXDbU+Ry4cmUjrGYT1s6tQq3HrlpMLVVOzK9xw2I2odojC+gJJaJ2a6weQbXHhkV1HrQpwt8XjOG3rx9DfyiuJnUB4CtXL8fNFy2ClhXKFQcArG2phMTlSVJAulKnXzPDuaHCgQqnFXaLST1Z+pWT00Aorlp0frf+RKql3udQrzBEcntpoxexpIRYUkK9T36NobAi/Eo+JJMaT7qN9oJaNxbVetT3572r5+BPN5+j/g/PRkj4ywTx5ekLxtUqk1/99WjO2vrx8OftnfjZS20YCMXhc8j2jBDCQCSBCqcVK5srAAB7OgPgnKN9MIJVTRXqc9QZ9KR3280Ix5M4qCTwHt7Wgd6RGM5ZWAOTieHWSxcDALwOK0wmhnqfA4FIAtFECjvah7CyqQI2iwkLauUv8Fy/C+9aXo973zyBf3tkFw50j+DVw32IJ+VoMZJIqXMBvvWBlbhx0zwAmjJLxQaaX5MWhJTEccn3XsK3n5Tfy3nVLjVyFRG/uOKQPX5ZEOJJOSoWf1e6bPj1x9fjkqV1AACr2QSLieHR7Z249r9fRziehNNqRoViRQBQ8hvD2DDfjzmVTiRSXK0djyYkXTL9WH9YZ5Wk3/e0kDdrItxqRdyOD8hXLyKCr/bY1ZNUjVIueaQvhIfebse6bzyHOx7dgyd2duoifiOuWZNeWe26DXNhs5gQTUjwOiw4PhBGz0gU5925Gf+lJPLnVDjBGENDhQNViriLk9NAKK7mRTKtHi3aq5U5ysl4Sb1X3Vbvc8DnsKKtN4hwPKVag5nUetP/q3d9cDV++pGpXz2tkJDwlwkdmiSliPp/v+UEHnp7dA32RAhEEkikOOIpCcsa5UiuZzim3lfhtMLnsKLCaUXXUBQDoTjiSQmrmivV56jXfCkFLpt8ElEjwFAcNosJlysTvT513gJ8/ZoV+O61qwEAdcoXsn0wgj2dw1ijzAReoFg8FS4rPrSuBYkUx4b5fiyq86B7OKbz9d9WGn8ta/ThE+fOBwAcVSo8hPcuhF+URvaH4ugejoEx4ANrm7HtxBBOBaLqSfaGjfPwlauXo8ptg8NiVnMODp3wW3Hhkjp8+oKFAOToWYjyzvYAogkJTptFtSIAYPuJIUgcWNdapV5VPLu3G06rGSYGPJpR3tlsIPynKbbVquYKXK7YZwDUCpcT/WG4bWbV6zYrJ1gAqPXYsbjei3hSwhce3KFG8RKHOokqG9rE57IGH649sxkA8O6VjeAceGZPN8LxlPp5iMDg9DkVWKR8nmKMfcGY+tlk5ky0aP/HxPulte3EVYW4Qp6bh/Ava/RisebkUQyMueYuURpoJ8cc7w9jTqVTTcjFkinDy1LOOR7e1oH3rJ6js2SM0HrOyxp92HJ0QJ2YE4gk1OiqscKBrkBEtSBWt6QjfiPhd9vMiCcl7O0cht9tw0AojsuW16uX+owx3KDMqgTS0evLB3sRT0pYrZxYzl5YjSX1XpxW74XfZcP3rl2NC5bU4p8e2IHu4agayQPA1mODsJoZ3DYzHJVOWEwMT+0+hef2dqPGa4fXblEv9Wu8dgxrErh+lw1Xr27E3c8dxJO7u9So9/SmCrxLEVWTicFlNSMUT8FhNakCWakc05nz5CoUq5nhe9euxjee2Iun93QjnpJkq8dhVU9EwgJb1VypzjLe1RHAhlY/YilpVBVXc9VoIVtU58X+r18xSqhFND0cTaonVEFDhQMdQxHUeOw4a4Ef0UQKlS4rLl/RgFVffQaRRGpM4QeABz69CY+80w6f04J/vES+evvIWfPwh7dO4hnN1Uq126Y+339dtwZMOXOKq5KBUFytlqp0Zbd6Girk/S0mpoq3y2bBXL8LJwbCqPfKyV3B0gZjQRefv91igmWals0sJCT8ZULHUATNVU60D0ZwYiCkRpkA0DUURWvNaC/znZND+MKDO+C0mXHVysZR92vRCr/4soj67GEl4gdk4e8ciqrWU2u1G16HBZLE1XJBLS57OqL+7IUL8eKBXnzinPlZx1GvRIVPK5N0xIllYa0HT3/+fHW/v1GiywafHfu7hnUlmpFECrVeOxhjsJjleQUv7JfbCyyq86DKbVPFpcZj1zUs87ttWFjrwZJ6L57d242LFdvGnXFsTuVKRo749YJlNjE8/rlz4bKZ0eJ34az51Xh6jyyCLptZF/HvaA9gQY0bFU4rzCYGxuSyyVXNFfA5rarwm00MKYkbRvyAcXTuslngspkRjqdGjV9U9tR4bXDZLPi7jfPU+6o9NrQPRnQefzY2zPdjgzIDt97nwDffvxIpicNhNeH1tr5RrwdAJ7Qiuu8PxnEsKn8OtZ7sy1iK4KLe51BLewHgtHovTgyEUackdwFgcZ1HN8lNizhpeB3FKaHFd6oiJkTHYARLG3yodFnxzJ5uPLk73Vu8I8uMSbGIeLbFzj/x67fwcWXWo1b4T2vwgjG5Pp9zrlo9ANBY6cSp4aha595Y6UCd124Y7QP6fjLr5/vxl1vPUyNiI0TN9VvHBlDjsauX81n39znQF4yprXXFF7laYxdofd6jfSFUKeJ+6bJ6XHBare75hBCd3lSBo30htY4/86TmVhK8Wqunwpl+zdObKlR7ShvBOoTHH0mAc44dJ4ewWkmae+wW/PJj63H3h1fjcxcvxiXL6tTHiauJbMKfjRblCkGMV9CofF7V7tEiK6LwsTz+bJhNDKfVe3UT37IJsM9hgdXMsL19CD9/+QiuPL1Bl7PIxGOXT2aZ/xeXLKvDWfP9cFjN6tWtOCEZIYQ/84RYLBTnqMuIiGIHiEvbbEQTKezuCGBdq/E/a+dQBJsWVuOcRYvxrSf3Y+vxQTVyzNYjJT2V3nhtUxEFc87VBmiALKZ+lw09IzFEEvLMVVX4fQ4MhOI42heC1cxQ47ZjaaMvaz94UfFS77PjbGUCTS4qXVbYzCbEUxLWtFSM+b7V+xyQONSe7T/9yBk4cGoEKzVJ59ZqNwA5YZqSOKpcVjisZvzvjevwwn59GwFhATRXySe4wXAcTqtZF10CaVF0Ws3q7WwWhbbcU0T8EperdHpGYljVnB7rRUvSYu9zpqtmKl1W9IfiqpDny9+c2YT//Mt+tZ2D4IZN87B8js/QAqxRTn7amcHjZUm9FzvbA2pVk7aSSAtjDH63DU/s7ILFxHDHe5bnfF7GGJY1+rBcU1EEANdvmIvrN8wFkJ5wuD7LdwlIf86iNLfYoIh/lhEIJ3DNj1/Foe4RJFMSlt3xFP7lj2Mv7fbQtnZc+/PXdX1khsJxtaeIqG/++Dnz8coXL8J3r12NX35sHRjL3hVRO5VecLQvNGqB7kM9QV2DsGq3DbVeO3pHYuqVgDbiB4BtJ4ZQ73PAZGK4+0Nr8IMPrzUcw7mLavCZCxfimdsuyKs8jjGmJgFXaxLH2RBVHmLewVnzq/HJ8xbgrAXpk8yG+X6dx+3XVI04NGNa3VyhVi41VznBubzQusfADhCRosNqSid3ncbCrz0huGxm1Hjl139MafUrIv5MGGN49OZz8NRt58HvtsFsYlkFNBui7j6zRcS8ajc+cEaz4WOEKDomUc64RLELz1tcgzPnVamzZo0QVx0r5viyXhloufdTZ+Hf370s6/2fvWghbrt0sW7iWSY+hwU2i8nQniwGinPUJcxrbX3Y0R7AN/+yD//5/pUAgD++3Y5bL1mcc/p3+2AEnAOHuoNorHBiKBzH+m8+h0SK446r5SjIaZPP8/U+Bz6oeNz1Xkf2iD+ob56VSEl4749exQ2b5uEL71qi7rdZifxPb5KjKIfVjFqvvNhGpvDPUYRnx8khbFAiqlyJ42qPHf96xdKs9xtR57WjfTCiVvTkQnjH+7pG4LFbDMdy1cpGXLWyEZu+9Ty6AlFUaWwghyLaPocFj95yrrpdfFZbjw1iXetoa0qIvcNqRpXLhus3tOCipXWj9gP0FpDTZsHpytXIL149Co/doiuJzUScFPxuGxorHONORFa6bPjh9WtR48leKZOJSAo7JhPxK8I/v8aNuz+8Jue+PqcsY/n2whkrgKjzOnDbpafl3IcxhlqP3fCkXgwU56hLEEni2NkRUC2BE/1h1QcHgFvu3YZvvn8lFtd7DP9xRUVHW28Q559WiyN9IdUjFdU1Rp5rU5UTHUNpDz+RkrC7I4C1c6tGdU1s6w1iJCYvmKLtJSP6qn/6/IV4j9JuodZrR1tPUI2khYffqPFWRbOyQiNea1XT2MIvrg46hiJo8eeOFuWKpKiuXFBEtTUZVS/CS09KHKfPGS3MWuE3mRi+9YFVWV9XG/E7rWY0V7kwr9qF4/1hXLqsLi8xv+3S03Sf2XgQLTTypboAEf+qpko0VTpz+uwCMbPX6AQ7lXz8nNasuanZDlk9s4SXDvXifT/5K95W1nk9MRBW/6G/cNlp2Ns1jKt/9Cr+49E9ho8XIi0qTLSX5qK+2W4k/JVOnZVz2/3b8f6fvoauQER9zsFwAuF4EnuUHjjtgxFdFcwbR+Rp91qBqvM60BuM4d4tJzCv2oW1SuSptd1iFCEAACAASURBVBounaJeJhctqcN7V89BRY6yPkGNOz0ZyZ9j4g+QPmnphFgR8JqMJGeDpmpkRZPeTwbS3nA+CdBMjx8AzllUo/s9FssafTh7YX77ThZxdSCuMCdChcuKv95+MTYuGDuvk1LyQ+tyJP2ngk+et0ANdIoNEv5ZQq8y2Wl/l5xkTEpcbTf7kY3z8MQ/nodWpZ+JESLiF42jAgb93LNF/F1DUaQkjnhSwhM75Wqf3pEYekdisCvWR+dQFLuVHjjtgxG1NYOYrAXoBarOa1faBgzibzfMVSf/OKxm/ODDa/DQZ86esi/Nh9a34IfXG+cMMjGZGM5dLAtiZu4iE1HJovP4lZJF4bsLLGaTepJbYRTxq1U9Y38Frea0lyxONO9aXg+rmeHCJcb20ExSCI9/PPz879bhy1cty1nNQ+gh4Z9BwvGkOolK9H8XE3MA4Ll93bBZTKhyWXFavRcNFQ6EY8Z95LuHc0T84RzCX+lEUuLoGYniOc1CF/2hOHqDMdVP7hySZ8KK5xYtfDdqGlFphf/0pgpYzQxnL6zGdevn6l7zfWubcpZkTjffVHIp82s8OfcTEb/W41fbGBiUNTZXOeGwmrDAYI6EaxwRP5B+b0XEf+GSOmz7ymW61hGzhWrP5Kt6xsPyOT586vwF0/JapQJ5/NPEPS+3odJpw4fWp7sT/viFw/jfV47ir7dfrC7SrK2Z39URwFy/Sy1JdNsshhG/WE/Va7egKxBFIJxQhd/vtqWF3+CLKHq3dAxGdCedY0qO4Kz5fuw4OYQHtp7E3s5h1Hhs6AvGsUOZMbpxQTV+9ddjAPTCv2G+Hwe/ceWY5ZSzgaZKJ1754kVjTsZZUu9VF4cROG1mpYXBaOG/etUcrJhTYejBCwE3st+MqHBa0TEU0Z0oxApYs43GCvmEl0+FDTEzUMQ/TTy8rQN/3qnvm/LSwV7EUxIe3d6hLsgtcXnCkOifom0q5bJbdEsaCkRPHDG79gM/+ys6BiPK9H6L6scbzc5sVqLYjqGIOgYg3R1xaaMPHz+nFY/v7EIsmcJnL5Q7LIqWyhs0tc6ZQlQMoi9o8btyNvcCgHMX12DLv12ia3tgt5jx209s0M1cFfyd0p/HCCH8+Ub8Iq8wXVH0ZKhwWvHa7ZfgytMbxt6ZmBEo4p8m4klJ5yEPhOLqoswPbevAyia9V76quQIHu4O6qepum1lt83uiP4zBsNxp82uPy4t7v3tVIzYu9OPz9+9AKJZChVOeaBRQbJlsHj8gC38wlkCVS57UJdaDrfHY8I+XLMbRvjCuXdeMM+dV4WuP78WujgAqnFad7ZE5SakUqTFoB5BvglWLsHry6WcDyMJvNjHdAjCzmVyN0oiZZ0zhZ4y1APgtgAYAEoB7OOf/xRjzA7gfQCuAYwA+xDkfnLqhFjexpKTz519v6wfnwOUr6vH0nm61yyMgC//6Vj/+740TOuF32Szqc9zx2G7s7ghgfatfXbSi3udQPd9Tw1EsbfDCaTNDTIo1SiS6bBZUuazoGIwgFEvC57TCxBj2KUnm5koXvA4r/vfGdQDkWboOq9w+t5q+3BNGtEDIt/Kl0mWDy2YuqqsoYvaSz39dEsAXOOfLAGwEcDNjbDmA2wE8zzlfDOB55W9Cw+/eOK62AohlRPw72odgs5hwhXI5rF0+rsJpxVnzq2ExMV2fGJcS8SdTErYeG0RfMK62TQDkShptT3uf06prxpbNJpBr+SMIxpLw2C2octsQSaTAmL45FiDbN+ctrlWPCQD+fMu5+NXH1o/vzSlznFYl4s+z8uUT58zHXR/MXutPEONhzIifc94FoEu5PcIY2wegCcA1AC5UdvsNgBcB/OuUjLIISaYkfOVPu/HJc+fj369ejlgyhZSUbmsQiafgtpnVpmLapG2F04qGCgeeuu083Wxdl90MicsnDXESiSUl3LBxHuZUOlXbRSRgK51WSJoeONn85KZKJ470ys3H5CZW8mMafA7Dmax3XL0cz+7tVks9VzZnnzlKGKNt0pYPi+o8ulW/CGIyjMvjZ4y1AlgLYAuAeuWkAM55F2PMsKCYMXYTgJsAYO7cuUa7lCSiR7tIrMaSEmKa+5OSBLPJpM5y1CKqYxbV6XuBi0k/YoUlj92CYCyJD69vUcsuAbmqoi8YR4XTiqimh042kZlT6cSrh/pgNZswp9IJYdVn62zZ4nfhoc9sGrW2KZE/S+q9WNbow2lZ+r0TxFSSd6aIMeYB8BCA2zjnw2PtL+Cc38M5X8c5X1dbWzv2A0oEUU7ZH4qDc3lyVDwp4Y0j/Xh+XzcSKQ6rmak1z1oyF98WCNvm5YO9aK5y4pJldXDbzKMWixD2TIXTCqfi6zMGNULPpMZjRyieQl8wBq/DoibmcrXwPXOeX20bTIyfOp8DT9563phtowliKsgr4meMWSGL/u855w8rm7sZY41KtN8IoCf7M5QfaeGPIZ5KR93X3fMGAOB9a+bAYmaoctnUxTNsFhPiSSlre17R0fFwTxBnzKvCl65cho+d3TqqTrxRI/wJ5bWd1uyJQZGk7RmJwWO3qK9jtD4rQRDFz5gRP5PV4hcA9nHOv6+56zEANyq3bwTwaOGHV7wI4R8IxtUkqJakxGE1mWA2MdUyaVGENlvEL5KzoXgKfrcNDRUOrJ07egasmDhT4bLCmccMUW3pncdhgd8tFu0YX+92giCKg3ysnnMA3ADgYsbYduXnKgDfBnAZY+wQgMuUv2cFtz+0E3/OWGR6uhnWWD2xhIHwpzgsZmXdUEV4RSvaWm+21ajSF2i56qQbdVbP2ElEbZ7BY7eoJ6LxrtZEEERxkE9Vz6sAshUPX1LY4RSGJ3Z1gTHMaOc8EfHHkhKGDNrhJiUJFpN83hUifuGSOnx0UyvOyNJHXluamauGXpSA1nkd6qzeXM3AtM/ldViwdm4lljX6DJuLEQRR/BTHNMBxEk9KhlH2dKJtktYZGN1fRyR3gfRsUJ/Dgo0LqrN68dr1Pf0GTcEEa1oq8cd/2ISNC/zqYhi5pvprE8weuwWL6rx48tbzaPYlQZQoJSf8nHPEU5Khrz6dDGuE/1Rg9ApXcjmnYvUowjtW0y3twuO5RJkxhnWtfjDGdGu7ZsNjt6itAIp1KTmCIPKn5IQ/KXFwDsSSxu2LpwtdxG+wWHkixdVqHCHiY3WHdGlEOd+l8LQrPWWDsXRZabEuJUcQRP6UnPCLSD86g1bPEzu70DEUUX31LoOIPyWlrR6RXB0r2tZG7fnaMPlE/Nrn883SVr8EQRSOkgvv4orwz1TEf3IgjJvv3QYAWNrgxf5TI+gy8PiTKQkWReivOr0Bw5HEmItqmE1M0yAtu8evxZlHxA/kf/IhCKL4KbmIPy380xvxB2NJ/NMD23XN1uZUOmGzmNTFyrXEkpIu4r/5okV5dV502yywmBh8zvwEOt+IX1T2kNVDEKVPyX3LVeGfJqsnJXFsPzmERErCw9s6dBFzhdOKKpcVPSOxUY+LJlJqOed4cNnNMJlY3u15nXlU9QAa4aeInyBKnpKL+IXFM11Wz7N7T+Fvfvaa2n5Zu3xhOJ6E12HVrWwliCRS6gSu8eC2WcbVBz+fCVwAcOnyely3viVrPx+CIEqHkgvvYtNs9YhFzkWt/rH+tPAf7QvpImjRiweQ2zJbJrBiVa3XDnuePdwBTcQ/hvBvXFCNjQuqxz0egiCKj5ITftEQbbqEX9uTB5AXLQeAKpcV/3L5Uvz29WPqvn6XTe27L0f844+uv/+hNRjP+cLrsMDrsKCx0rgNBEEQ5UfpCb9azpnCT188jAqnFR85a/RC2LnYcqQfSxq8Yy6+DWiEX2nLIHHAZjZh21cuA2MMf3qnQ93X704Lv3bm7nio9eZXzSOwW8x45YsXjTk5jCCI8qHkDF2t1fOndzrw2PbxNWsLhBP48D1v4AsP7MhvfyH8oXQ/Hp/TqiZftZOy/vXKpfjA2ib174kkdydCpctWFguhEwSRHyUn/CLiT0kcgUgCQ+HEGI/Qs7NjCADQFxrdWC0QTuBURk2+kfBr++lrhf/8xTW4YEl6MZqJJHcJgiAmS8laPQAwGEpAs+RsXuw4KQv/0vrRS+Kdd+cLGI4mcfAbV+Klg73qyQXQC7+2n76wWOwWExhjsGp8fesEPH6CIIjJUnrCn0ppbksYCifAOR9V994xFMHPX2rDHVcv1yVZd7QHABi3MRbr6N7zchu++8xBAMAcpfe9tjdPpUb4RVWPKJPUVvKQ/UIQxExQciFn5sSteEpCOD66pv/fHt6F375+HK8f6ddtFxF/PJX9UqEvmI7ujVou6yN+WfhtSgmmLuIn4ScIYgYowYh/dBnnYDiu62UPpKNt7YliKBxXZ9kKy+h4fwhOm1m3+lU4PnpClpYKl7HVA+iFfyLlnARBEJOl5JQnblC/b5TgFUKsrffX2jVikfKb792Gbz6xD+2D6X47w5FkztYG2ojfp0T8dsU60iZ0KblLEMRMUHLCbzRxa9Bg6UObIvzanIC2tYI4gfSOxNAXjOHkQLr52kAojha/K2sdfqVhcldYPenHWKepnJMgCEJLySmPsfDniPg1Vs+wQcQ/HEkiGE3i5GBa+PtDMXjsZjRW6BcjF2WcVZpeOh7V4xfJXa3VQxE/QRDTT+l5/IZWT66IXyP8SsTvsJoQT0lIpCREEimMxJI6q6c/FMecSifmVDpwQnMlsKalEpevaMBly+vVbSK5q1b16KyekjvvEgRRBJSM8CdSEqxmk6HwD4aMIn7ZetFG/CNReb9qtx2xpKRaP8FoEu2aiD8QScBlM8Ntk9snWM0MiRSHy2bG9Rvm6l4nU/h1yV2q6iEIYgYoiZAzGEti8ZefxE82HzZsx2zk8aeTu6M9/mqPDYmUpJ4IgrEk+jUlnJwDLpsFcyplq6fOK9fyG7U+tlvMsFlMJPwEQcwaSkL4B5VZs3c9fWBUxO+xWwytHjXiT2qtHlno/W4b4kkJwxH5RBCOpzAQiqPGk26Q5rSZcXqTD26bGa01LgDphc0z8Tks6utpxZ5m7hIEMROUhPIkpfRkq78e7tPNum2uchomd4Xmak8UI9Ek3DYznFazLuIHgPahCBor0q2NXVYzLl/RgK3/fpka8Wfreb+6uRJLGuQWEPo6for4CYKYfkrC409oErSdgShqvXZEEzFYTAzVHhuCsdETrsRDYkm9x+91WNVcwbBG+ONJCY0VDuzqkFs6uGxmMMbgtJlViyeb8P/iY+vV27rkLpVzEgQxA5SE8mTaOyKh6rZbYDaZdFcEgpTSvU3r8Q9HkvA5LbBZTEikuFrlIxCePgA4NTN5hcXjGGNdW0Bfuz+RfvwEQRCTpSSEP5HKFH65nt5jt8BiYpAMhF9si2j6+IzE0hF/LCnp6voBoEFr9WhE3pXn8oYAYLVQOSdBEDNLSShPQmmoJhpwOq0mWM0MLpsZZhMzjPglJeLXNnAbiSbhdVhgt5gUj18f8Ws9fq3Ij2X1aNFN4KKqHoIgZoASEX454m9SrBibxQy7xSxbPYwhJY2u7RdWTySRKfxWWM1slMcPAA0+R/rkYhTx52P16Dx+En6CIKafkhB+MftWePA2s1w377FbYDYzpPK0eoYjCfgcwuOXI36tOFe5bWpUr7V6xDajOv5MGGNqZ1CyegiCmAlKQnkSSnK3WRH+WDIFu8UEl80Mi8lY+EVaYLTVY4XNbEZS4hgKJ1DvS9s7lU6rKvLa6N45Do8fSEf6lNwlCGImGFP4GWO/ZIz1MMZ2a7Z9lTHWwRjbrvxcNbXDzI3w+EXEH4gkcGarH2vnVsHMcnv8UcXqiSZSiKckeB0WNQHbH4qhoSJt71S4rGpU79JV9ci387F6APmKBKByToIgZoZ8lOfXAK4w2H4353yN8vOXwg5rfCQyrJ5AJIEfXb8Wn7lwIcxZI359clf4+T6nVRXm/mAcFU4rPDYLXDY5byAsHq3Vs761Ch9a14wVc3x5jVfU8lPETxDETDCm8HPOXwYwMA1jmTDC42+qkoVfW4ZpyeLxZyZ3H9veCQBYUONWO3f2B2PwOizwOCxqj30jW6fSZcOdH1ytuwrIhfD2yeMnCGImmIzy3MIY26lYQVXZdmKM3cQY28oY29rb2zuJl8tOuqpn9MLn2SJ+ztPJ3cFQHHc/exAXLanF2Qur1Yg/FE/B57DCY7egwiX32DdK7o4XsdYuVfUQBDETTFT4fwZgIYA1ALoAfC/bjpzzezjn6zjn62prayf4crkRyV2/W26i9olz5qv3ZfP4xckgnpJwqCeIUDyFj25qBWNM10/H67Cg1mtHg09+buc4SjezkY74SfgJgph+JtSrh3PeLW4zxv4HwOMFG9EEEMldm8WEo9+6CoylBdVsMhnO3NVO9u0Lygus+5z61bLkbVbcde1qmNTJYUrppmUywi8ifrJ6CIKYfiYk/IyxRs55l/Ln+wHszrX/VCM8fquZ6UQfkEU2V1UPIK+rCwAeu+zja4Xf67CoE8MAOdJ3Ws0wTcKmEVYSJXcJgpgJxhR+xth9AC4EUMMYawfwHwAuZIytAcABHAPw6Skc45gIj99o8XITy13VAwA9I1EAgNsuR/E2jdXjc1h1j5tT4URjpQOTQY34KblLEMQMMKbwc86vN9j8iykYy4RJpCRYTMwwCreYGJKalg1tvUG8dKBXreoBgJ5hOeL3Zon4tdxy8SJ88rz5mAzC4qHkLkEQM0FJhJyJFM+6mpXZxCDxdBXPY9s78bXH96oJYQA4NayP+PXJXX3E77CaUalU+EwUq1rHXxJvP0EQRUZJKE88KWX1y0VULawd8Vvbyrl9MAKH1aRaL9qIv8JZ+LVqRMRPAT9BEDNBSQh/IiXpxFqLsH9EgldYPPGUBJ9i43QMRuCxpwVeexLJjPgLgdViMkxEEwRBTAclI/zZbBMR8YsqHlHaGU9K8LtlyyaeknTCb7dkT+4WAquJUSknQRAzRkmoz1geP5CO+JMa4fc5rer9bo3w28yy128xMd3C7YXCYmY0eYsgiBmjJIQ/nsru8QthT6X0Hn8sKcFsYmoPHp3Vo3Tn9DmtU2LHWMwmSuwSBDFjlIT6JJJjWz0i0pc0Hr+ZMVS4Rgu/qOPPLOUsFLLVQxE/QRAzQ2kIf47krlnx0oXgpzRWj0kb8Tu0Ef/UCv+cSicaNbOBCYIgppOpUbZpJill9/gzI35tOaeZMbgV4XcbRPxTkdgFgH+67DT84yWjZxMTBEFMByUh/Lnq+E1ZPP648PiVyVjeabR6LGYTJtHjjSAIYlKUjNUzdsQvT9hS6/gVq6fCILlrUjz4qYr4CYIgZpISEX6ua6ymxZxRx5+2ejhMDKh0jbZ6AHl7ndKDnyAIopQoCasnV8SfWcevXYDFzIyTuwDwh5s2kfATBFGSlITwx1OSWomTiSr8KX05JyBbOsLj92RE/IvqPFMxVIIgiBmnRKyesZu0CcEXJwBAXpaxwqCqhyAIopQpDeFPju3xZ07gEvetn+/HRzfNw5nzsq4XTxAEUVKURJibj8ef2ZYZkK0ej92Cr11z+tQPkiAIYpZQEhF/PJ/kbkrfpA0AqE8aQRDlSEkIfyIlqY3VMrFktGzQJXepHz5BEGVIiQh/Lo9f/p1ZzgnAcI1egiCIUqfohT8lcaRy9OoRTdpSYuaupK/qIQiCKDeKXvjF2rljtWwQS+xSxE8QRLlTQsI/xkIsaq8e7X1TOzaCIIjZSNFLX0JR8uz9+DNbNkjp+8jqIQiiDCkB4c9t9Yyu40/fR1YPQRDlSNELfzyZr8evlHNKVM5JEER5U/zCn6fHL6yepNbqoYifIIgypOiF/1QgCgCo8Ri3UM60ejQBP0X8BEGUJUUv/G29QQDZ2yjn6tVDVT0EQZQjRS99h3uC8NgtqPMaR/wWdQKXgfBTxE8QRBlS9MLf1hvEwjoPWBYRF+JOLRsIgiBkil/4e0JYWOvOer/ZnDmBiyJ+giDKmzGFnzH2S8ZYD2Nst2abnzH2LGPskPJ7RlYxGYkmcGo4ioW12ZdJpJYNBEEQevKJ+H8N4IqMbbcDeJ5zvhjA88rf087x/jAAYEFNjog/s2UD1fETBFHmjCn8nPOXAQxkbL4GwG+U278B8L4CjysvgrEkAKjr5hqR6fFLVNVDEESZM1Hpq+ecdwGA8rsu246MsZsYY1sZY1t7e3sn+HLGxJRZu3Zr9sMwmRgYSwt+kiJ+giDKnCmPeTnn93DO13HO19XW1hb0uUW7BpvZnHM/i4mlq3oyFlsnCIIoNyYq/N2MsUYAUH73FG5I+RNLpgDkjvgBObI36tVDwk8QRDkyUeF/DMCNyu0bATxamOGMj3TEn/swtBE/WT0EQZQ7+ZRz3gfgdQBLGGPtjLG/B/BtAJcxxg4BuEz5e9rJx+MH5Mg+JXFdtC+2EwRBlBuWsXbgnF+f5a5LCjyWcZN3xG82yWvzcr3wk+4TBFGOFHVBY9rjz53cNTHZ6klJmcJPyk8QRPlR1MI/Ho9fMhB+snoIgihHSkL4sy3CIjAryd1Mq4eEnyCIcqSohT+WlGC3mLJ25hTIyV0JqRRZPQRBEEUv/DbL2IdgoYifIAhCpeiF327JndgFZIGX+OhyTor4CYIoR4pa+OOK1TMWZhND+2AE208O6bZTwE8QRDlS1MIfS6byFv6d7QHc9Lu3R20nCIIoN4pa+OPj8PiNoIVYCIIoR4pa+GPjsHoMt5PHTxBEGVLUwp9vxJ+R01Uhq4cgiHKkqIVf9vjHrurpC8YMt1NVD0EQ5UhRC388lV/E3z0c1f0tIn2K+AmCKEeKWvhjifw8/kTGjF3R24fW3CUIohwpaunLN+LPRDxmrFYPBEEQpUhxC3+eVT2ZCOGnqh6CIMqRohb+fHv1/L/3rkCNx6b+nbZ6SPgJgig/ilr443n26rnx7Fbc+cFV6t9iqUaq6iEIohwpauGPJVN5e/zaEwRF/ARBlDNFK/ySxJFI8bw9fu1+4jZV9RAEUY4UrfTFU8qyixOI+MVtsnoIgihHilb4Y8qyi/l4/EDa1wfSJwsSfoIgypEiFv4UgPFE/KOFnzx+giDKkaIV/rga8U/E6lEifhJ+giDKkKIV/ti4hd8g4ierhyCIMqRohX/cEb/W4zeLiL/w4yIIgpjtFK30iYh/QlU9Vor4CYIoX4pW+OPjrOrRJnJtZvOobQRBEOWCZaYHMFHi44z4tVy0tBYpSYLPYS30sAiCIGY9RSv8I9EEAMBtG/8hLG3w4bzFtYUeEkEQRFFQtFbPQDgOAKjWdN3MF7J4CIIoZ4pX+IOy8Fe6xm/XUFKXIIhyZlJWD2PsGIARACkASc75ukIMKh8GwnF47Za8k7tazGYSfoIgypdCePwXcc77CvA842IwFEeVe/w2D0ARP0EQ5U3RWj39kxB+mrhFEEQ5M1kJ5ACeYYy9zRi7yWgHxthNjLGtjLGtvb29k3y5NIPhOPwT8PcBivgJgihvJiv853DOzwBwJYCbGWPnZ+7AOb+Hc76Oc76utrZwJZSDoQT8bvuEHktVPQRBlDOTEn7OeafyuwfAIwA2FGJQ+dAfisHvnljEzyjiJwiijJmw8DPG3Iwxr7gN4F0AdhdqYLmIxFOIJqQJe/wEQRDlzGSqeuoBPKJEzxYA93LOnyrIqMagPxQDAPhdJPwEQRDjZcLCzzk/AmB1AceSN4MhuV2Df5wRP2MA51MxIoIgiOKhKHv1iHYN4xX+zV+4EPtPjUzFkAiCIIqGohT+wZBo1zA+4W+tcaO1xj0VQyIIgigainIq07DSmbPCSW2VCYIgxktxCn9EFn6fsygvWAiCIGaUohT+QCQBh9U0oQZtBEEQ5U5RCv9wJEmrZxEEQUyQ4hT+aIL8fYIgiAlStMLvI+EnCIKYEEUp/IFIAj4HJXYJgiAmQlEK/3AkSVYPQRDEBClO4SerhyAIYsIUnfBLEsdwJEFVPQRBEBOk6IQ/FE9C4jRrlyAIYqIUnfAPR5MAaNYuQRDERCkq4d+8vwfnfPsFACCrhyAIYoIUlfB/56n96m2yegiCICZGUQl/U6VTvU1VPQRBEBOjqIS/KxBVb3vs5PETBEFMhKJSz5ODYWxaUI3mKieaq5xjP4AgCIIYRdEIfyCSwEg0iYuX1uFT5y+Y6eEQBEEULUVj9ZwcCAMARfoEQRCTpGiEv30wAgBo8btmeCQEQRDFTREJvxzxt1SR8BMEQUyGohH+tt4QKpxWmrFLEAQxSYpG+Pd1DWNZoxeMsZkeCkEQRFFTFMKfkjgOnBrB8saKmR4KQRBE0VMUwn+sP4RIIoVljd6ZHgpBEETRUxTCv69rGACwrNE3wyMhCIIofopC+Pd2DsNiYlhc75npoRAEQRQ9RSH8c/0ufOCMJtgt5pkeCkEQRNFTFLWR122Yi+s2zJ3pYRAEQZQERRHxEwRBEIVjUsLPGLuCMXaAMXaYMXZ7oQZFEARBTB0TFn7GmBnATwBcCWA5gOsZY8sLNTCCIAhiaphMxL8BwGHO+RHOeRzAHwBcU5hhEQRBEFPFZIS/CcBJzd/tyjYdjLGbGGNbGWNbe3t7J/FyBEEQRCGYjPAbNc3hozZwfg/nfB3nfF1tbe0kXo4gCIIoBJMR/nYALZq/mwF0Tm44BEEQxFQzGeF/C8Bixth8xpgNwHUAHivMsAiCIIipgnE+yp3J/8GMXQXgBwDMAH7JOf/mGPv3Ajg+gZeqAdA3gcfNZuiYigM6puKg1I9pHue8YF75pIR/umCMbeWcr5vpcRQSOqbigI6pOKBjGh80c5cgCKLMIOEnCIIoM4pF+O+Z6QFMAXRMxQEdU3FAxzQOisLjJwiCIApHsUT8BEEQRIEg4ScIgigzZr3wF1PrZ8bYMcbYLsbYdsbYVmWbnzH2LGPskPK7StnOGGM/VI5rJ2PsDM3z3Kjsf4gxduMMHMcvGWM9jLHdmm0FOw7Gc+zJpAAABFZJREFU2JnK+3RYeaxR+4/pOKavMsY6lM9ruzIvRdz3JWV8Bxhjl2u2G/4/KhMZtyjHer8yqXEqj6eFMbaZMbaPMbaHMXarsr1oP6ccx1TMn5ODMfYmY2yHckz/L9c4GGN25e/Dyv2tEz3WnHDOZ+0P5IlhbQAWALAB2AFg+UyPK8d4jwGoydh2J4Dbldu3A/iOcvsqAE9C7nm0EcAWZbsfwBHld5Vyu2qaj+N8AGcA2D0VxwHgTQCblMc8CeDKGTqmrwL4Z4N9lyv/a3YA85X/QXOu/0cADwC4Trn93wA+M8XH0wjgDOW2F8BBZdxF+znlOKZi/pwYAI9y2wpgi/L+G44DwGcB/Ldy+zoA90/0WHP9zPaIvxRaP18D4DfK7d8AeJ9m+2+5zBsAKhljjQAuB/As53yAcz4I4FkAV0zngDnnLwMYyNhckONQ7vNxzl/n8n/0bzXPNWVkOaZsXAPgD5zzGOf8KIDDkP8XDf8flUj4YgB/VB6vfX+mBM55F+d8m3J7BMA+yN1xi/ZzynFM2SiGz4lzzoPKn1blh+cYh/bz+yOAS5Rxj+tYxxrXbBf+vFo/zyI4gGcYY28zxm5SttVzzrsA+R8bQJ2yPduxzdZjLtRxNCm3M7fPFLco1scvhS2C8R9TNYAhznkyY/u0oNgBayFHkyXxOWUcE1DEnxNjzMwY2w6gB/KJtS3HONSxK/cHlHEXVC9mu/Dn1fp5FnEO5/wMyKuS3cwYOz/HvtmOrdiOebzHMZuO72cAFgJYA6ALwPeU7UVzTIwxD4CHANzGOR/OtavBtmI5pqL+nDjnKc75GsgdjDcAWJZjHNNyTLNd+Iuq9TPnvFP53QPgEcgfcrdy2Qzld4+ye7Zjm63HXKjjaFduZ26fdjjn3cqXUgLwP5A/L2D8x9QH2TqxZGyfUhhjVsgC+XvO+cPK5qL+nIyOqdg/JwHnfAjAi5A9/mzjUMeu3F8B2aIsrF5MZWJjsj8ALJCTTfORTlysmOlxZRmrG4BXc/s1yN78XdAn2+5Ubr8b+mTbm8p2P4CjkBNtVcpt/wwcTyv0idCCHQfklt4bkU4aXjVDx9Souf15yB4qAKyAPpF2BHISLev/I4AHoU/WfXaKj4VB9t1/kLG9aD+nHMdUzJ9TLYBK5bYTwCsArs42DgA3Q5/cfWCix5pzXFP9ZSvAG3cV5Ox+G4Avz/R4coxzgfKm7wCwR4wVsj/3PIBDym/xpWKQF6tvA7ALwDrNc30CcvLmMICPz8Cx3Af5kjoBOaL4+0IeB4B1AHYrj/kxlBnkM3BMv1PGvBPyWhJagfmyMr4D0FSzZPt/VD7/N5VjfRCAfYqP51zIl/Q7AWxXfq4q5s8pxzEV8+e0CsA7yth3A7gj1zgAOJS/Dyv3L5joseb6oZYNBEEQZcZs9/gJgiCIAkPCTxAEUWaQ8BMEQZQZJPwEQRBlBgk/QRBEmUHCTxAEUWaQ8BMEQZQZ/x+nQbisr07dbQAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sequential(\n",
      "  (0): Conv2d(1, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "  (1): ReLU()\n",
      "  (2): Conv2d(32, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "  (3): Dropout(p=0.1, inplace=False)\n",
      "  (4): ReLU()\n",
      "  (5): Conv2d(64, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "  (6): Dropout(p=0.2, inplace=False)\n",
      "  (7): ReLU()\n",
      "  (8): AdaptiveMaxPool2d(output_size=(1, 1))\n",
      "  (9): Flatten()\n",
      "  (10): Linear(in_features=128, out_features=128, bias=True)\n",
      "  (11): Dropout(p=0.5, inplace=False)\n",
      "  (12): ReLU()\n",
      "  (13): Linear(in_features=128, out_features=128, bias=True)\n",
      "  (14): Dropout(p=0.5, inplace=False)\n",
      "  (15): ReLU()\n",
      "  (16): Linear(in_features=128, out_features=4, bias=True)\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "#to load the saved model\n",
    "with open('models/bestest_model.pickle', 'rb') as f:\n",
    "     data = pickle.load(f)\n",
    "\n",
    "model = data[0].to(DEFAULT_DEVICE)        \n",
    "agent.qnet= data[0]\n",
    "\n",
    "plt.plot(data[1], data[2])\n",
    "plt.show()\n",
    "print(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "agent.qnet = torch.load(\"models/best_model.h5\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Visualize and Record Gameplay"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Completed: True\n",
      "episode: 0 Food Collected: [12]\n",
      "Completed: True\n",
      "episode: 1 Food Collected: [18]\n",
      "Completed: True\n",
      "episode: 2 Food Collected: [22]\n",
      "Completed: True\n",
      "episode: 3 Food Collected: [18]\n",
      "Completed: True\n",
      "episode: 4 Food Collected: [19]\n",
      "Completed: True\n",
      "episode: 5 Food Collected: [25]\n",
      "Completed: True\n",
      "episode: 6 Food Collected: [33]\n",
      "Completed: True\n",
      "episode: 7 Food Collected: [24]\n",
      "Completed: True\n",
      "episode: 8 Food Collected: [24]\n",
      "Completed: True\n",
      "episode: 9 Food Collected: [22]\n",
      "Completed: True\n",
      "episode: 10 Food Collected: [20]\n",
      "Completed: True\n",
      "episode: 11 Food Collected: [22]\n",
      "Completed: True\n",
      "episode: 12 Food Collected: [21]\n",
      "Completed: True\n",
      "episode: 13 Food Collected: [24]\n",
      "Completed: True\n",
      "episode: 14 Food Collected: [23]\n",
      "Completed: True\n",
      "episode: 15 Food Collected: [16]\n",
      "Completed: True\n",
      "episode: 16 Food Collected: [13]\n",
      "Completed: True\n",
      "episode: 17 Food Collected: [16]\n",
      "Completed: True\n",
      "episode: 18 Food Collected: [21]\n",
      "Completed: True\n",
      "episode: 19 Food Collected: [19]\n",
      "Completed: True\n",
      "episode: 20 Food Collected: [19]\n",
      "Completed: True\n",
      "episode: 21 Food Collected: [25]\n",
      "Completed: True\n",
      "episode: 22 Food Collected: [25]\n",
      "Completed: True\n",
      "episode: 23 Food Collected: [23]\n",
      "Completed: True\n",
      "episode: 24 Food Collected: [33]\n",
      "Completed: True\n",
      "episode: 25 Food Collected: [27]\n",
      "Completed: True\n",
      "episode: 26 Food Collected: [24]\n",
      "Completed: True\n",
      "episode: 27 Food Collected: [18]\n",
      "Completed: True\n",
      "episode: 28 Food Collected: [24]\n",
      "Completed: True\n",
      "episode: 29 Food Collected: [26]\n",
      "Completed: True\n",
      "episode: 30 Food Collected: [12]\n",
      "Completed: True\n",
      "episode: 31 Food Collected: [20]\n",
      "Completed: True\n",
      "episode: 32 Food Collected: [22]\n",
      "Completed: True\n",
      "episode: 33 Food Collected: [14]\n",
      "Completed: True\n",
      "episode: 34 Food Collected: [27]\n",
      "Completed: True\n",
      "episode: 35 Food Collected: [16]\n",
      "Completed: True\n",
      "episode: 36 Food Collected: [18]\n",
      "Completed: True\n",
      "episode: 37 Food Collected: [12]\n",
      "Completed: True\n",
      "episode: 38 Food Collected: [13]\n",
      "Completed: True\n",
      "episode: 39 Food Collected: [30]\n",
      "Completed: True\n",
      "episode: 40 Food Collected: [12]\n",
      "Completed: True\n",
      "episode: 41 Food Collected: [16]\n",
      "Completed: True\n",
      "episode: 42 Food Collected: [14]\n",
      "Completed: True\n",
      "episode: 43 Food Collected: [24]\n",
      "Completed: True\n",
      "episode: 44 Food Collected: [28]\n",
      "Completed: True\n",
      "episode: 45 Food Collected: [20]\n",
      "Completed: True\n",
      "episode: 46 Food Collected: [18]\n",
      "Completed: True\n",
      "episode: 47 Food Collected: [16]\n",
      "Completed: True\n",
      "episode: 48 Food Collected: [15]\n",
      "Completed: True\n",
      "episode: 49 Food Collected: [27]\n",
      "Completed: True\n",
      "episode: 50 Food Collected: [32]\n",
      "Completed: True\n",
      "episode: 51 Food Collected: [21]\n",
      "Completed: True\n",
      "episode: 52 Food Collected: [25]\n",
      "Completed: True\n",
      "episode: 53 Food Collected: [13]\n",
      "Completed: True\n",
      "episode: 54 Food Collected: [21]\n",
      "Completed: True\n",
      "episode: 55 Food Collected: [19]\n",
      "Completed: True\n",
      "episode: 56 Food Collected: [22]\n",
      "Completed: True\n",
      "episode: 57 Food Collected: [5]\n",
      "Completed: True\n",
      "episode: 58 Food Collected: [25]\n",
      "Completed: True\n",
      "episode: 59 Food Collected: [18]\n",
      "Completed: True\n",
      "episode: 60 Food Collected: [15]\n",
      "Completed: True\n",
      "episode: 61 Food Collected: [12]\n",
      "Completed: True\n",
      "episode: 62 Food Collected: [0]\n",
      "Completed: True\n",
      "episode: 63 Food Collected: [17]\n",
      "Completed: True\n",
      "episode: 64 Food Collected: [14]\n",
      "Completed: True\n",
      "episode: 65 Food Collected: [29]\n",
      "Completed: True\n",
      "episode: 66 Food Collected: [24]\n",
      "Completed: True\n",
      "episode: 67 Food Collected: [22]\n",
      "Completed: True\n",
      "episode: 68 Food Collected: [21]\n",
      "Completed: True\n",
      "episode: 69 Food Collected: [24]\n",
      "Completed: True\n",
      "episode: 70 Food Collected: [16]\n",
      "Completed: True\n",
      "episode: 71 Food Collected: [20]\n",
      "Completed: True\n",
      "episode: 72 Food Collected: [20]\n",
      "Completed: True\n",
      "episode: 73 Food Collected: [31]\n",
      "Completed: True\n",
      "episode: 74 Food Collected: [24]\n",
      "Completed: True\n",
      "episode: 75 Food Collected: [26]\n",
      "Completed: True\n",
      "episode: 76 Food Collected: [14]\n",
      "Completed: True\n",
      "episode: 77 Food Collected: [27]\n",
      "Completed: True\n",
      "episode: 78 Food Collected: [31]\n",
      "Completed: True\n",
      "episode: 79 Food Collected: [26]\n",
      "Completed: True\n",
      "episode: 80 Food Collected: [29]\n",
      "Completed: True\n",
      "episode: 81 Food Collected: [26]\n",
      "Completed: True\n",
      "episode: 82 Food Collected: [14]\n",
      "Completed: True\n",
      "episode: 83 Food Collected: [21]\n",
      "Completed: True\n",
      "episode: 84 Food Collected: [26]\n",
      "Completed: True\n",
      "episode: 85 Food Collected: [29]\n",
      "Completed: True\n",
      "episode: 86 Food Collected: [22]\n",
      "Completed: True\n",
      "episode: 87 Food Collected: [15]\n",
      "Completed: True\n",
      "episode: 88 Food Collected: [21]\n",
      "Completed: True\n",
      "episode: 89 Food Collected: [21]\n",
      "Completed: True\n",
      "episode: 90 Food Collected: [24]\n",
      "Completed: True\n",
      "episode: 91 Food Collected: [13]\n",
      "Completed: True\n",
      "episode: 92 Food Collected: [16]\n",
      "Completed: True\n",
      "episode: 93 Food Collected: [21]\n",
      "Completed: True\n",
      "episode: 94 Food Collected: [21]\n",
      "Completed: True\n",
      "episode: 95 Food Collected: [16]\n",
      "Completed: True\n",
      "episode: 96 Food Collected: [9]\n",
      "Completed: True\n",
      "episode: 97 Food Collected: [24]\n",
      "Completed: True\n",
      "episode: 98 Food Collected: [19]\n",
      "Completed: True\n",
      "episode: 99 Food Collected: [27]\n",
      "Wall time: 2min 25s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "env = SingleSnake(num_envs=1, size=10, observation_mode='one_channel', device= DEFAULT_DEVICE)\n",
    "agent.evaluate()\n",
    "PATH = os.getcwd()\n",
    "state = env.reset()\n",
    "for episode in range(100):\n",
    "    fc_sum = 0\n",
    "    recorder = VideoRecorder(env, path=PATH + f'/videos/snake_{episode}.mp4')\n",
    "    #env.render()\n",
    "    recorder.capture_frame()\n",
    "    time.sleep(0.2)\n",
    "    counter = 0\n",
    "    while(1):\n",
    "        counter+=1\n",
    "        action = agent.epsilon_greedy_action( state , 0.0)\n",
    "        next_state, reward, terminal, _ = env.step(action)\n",
    "        fc_sum+= (reward>0).cpu().numpy()\n",
    "        #env.render()\n",
    "        recorder.capture_frame()\n",
    "        #time.sleep(0.2)\n",
    "        state = next_state\n",
    "        if terminal.all() or counter==1000:\n",
    "            recorder.close()\n",
    "            break\n",
    "    print(\"Completed:\", terminal.any().cpu().numpy())\n",
    "    print('episode:', episode, 'Food Collected:', fc_sum)\n",
    "\n",
    "#env.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'NoneType' object has no attribute 'window'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-10-0a65a13f4d3e>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[0mrecorder\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mclose\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 2\u001b[1;33m \u001b[0menv\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mclose\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m~\\OneDrive - University of Bath\\Reinforcement Learning\\Fast Snake\\wurm\\envs\\simple_gridworld.py\u001b[0m in \u001b[0;36mclose\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    364\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    365\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mclose\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 366\u001b[1;33m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mviewer\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mwindow\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mclose\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    367\u001b[0m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mviewer\u001b[0m\u001b[1;33m=\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    368\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mAttributeError\u001b[0m: 'NoneType' object has no attribute 'window'"
     ]
    }
   ],
   "source": [
    "recorder.close()\n",
    "env.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Computing Average Return"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Completed: 1280\n",
      "Mean, Median, Max, Min, std: 0.053076923 0.0 1.0 0.0 0.22418688\n"
     ]
    }
   ],
   "source": [
    "test_env = SimpleGridworld(num_envs=num_envs, size=10, observation_mode='one_channel', device= DEFAULT_DEVICE, auto_reset=False)\n",
    "agent.evaluate()\n",
    "\n",
    "                       \n",
    "t_state = test_env.reset()\n",
    "fc_sum = torch.zeros((num_envs,)).float().to(DEFAULT_DEVICE) #foot collected\n",
    "\n",
    "for steps in range(1000): #max steps\n",
    "    t_action = agent.epsilon_greedy_action( t_state , 0.0)\n",
    "    t_next_state, t_reward, t_terminal, _ = test_env.step(t_action)\n",
    "    #anything with a positive reward is considered as food.\n",
    "    fc_sum+=(t_reward>0).float()\n",
    "    t_state = t_next_state\n",
    "    if t_terminal.all():\n",
    "        break\n",
    "\n",
    "t_sum = fc_sum.cpu().numpy()\n",
    "t_mean = np.mean(t_sum)\n",
    "print(\"Completed:\", t_terminal.sum().cpu().numpy())\n",
    "print(\"Mean, Median, Max, Min, std:\", \n",
    "      t_mean, \n",
    "      np.median(t_sum),\n",
    "      np.max(t_sum),\n",
    "      np.min(t_sum),\n",
    "      np.std(t_sum))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
